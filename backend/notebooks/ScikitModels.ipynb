{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0beb9530-f3f0-464a-a46c-6c5bbb9fc433",
   "metadata": {},
   "source": [
    "## Sci-kit dataset preparation as matrix\n",
    "\n",
    "This notebook shows how to prepare the datasets for sci-kit based models. Sci-kit's API is very consistent, and it should work \"out of the box\" when given numeric (2D) matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bae21c38-91b1-4b10-9147-58a1debfe3a2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -q seaborn molfeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe9ba0df-527c-44d6-befe-1cb112946cca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import Literal, Union, Dict\n",
    "\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from humps import camel\n",
    "from pydantic import BaseModel\n",
    "import numpy as np\n",
    "import sklearn.base\n",
    "\n",
    "from fleet.base_schemas import BaseModelFunctions\n",
    "from fleet.model_builder.utils import get_references_dict\n",
    "from fleet.dataset_schemas import DatasetConfigBuilder, DatasetConfig\n",
    "from fleet import data_types\n",
    "from fleet.utils import data\n",
    "from fleet.yaml_model import YAML_Model\n",
    "from fleet.model_builder.utils import get_class_from_path_string\n",
    "from fleet.model_builder import splitters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "200281ad-bd78-4fe0-b4eb-8a8552562a5f",
   "metadata": {},
   "source": [
    "### Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3eaec021-c125-4878-92a6-39909754ef5f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! [ ! -f HIV.csv ] && wget https://deepchemdata.s3-us-west-1.amazonaws.com/datasets/HIV.csv\n",
    "! [ ! -f SAMPL.csv ] && wget https://deepchemdata.s3-us-west-1.amazonaws.com/datasets/SAMPL.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b22f97f8-39b8-4f54-abce-cf717eb3baa1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hiv_df = pd.read_csv('HIV.csv')\n",
    "sampl_df = pd.read_csv('SAMPL.csv')\n",
    "\n",
    "if 'step' not in hiv_df.columns:\n",
    "    splitters.apply_split_indexes(\n",
    "        hiv_df,\n",
    "        split_type=\"scaffold\",\n",
    "        split_column=\"smiles\",\n",
    "        split_target=\"80-10-10\")\n",
    "    hiv_df.to_csv('HIV.csv', index=False)\n",
    "\n",
    "if 'step' not in sampl_df.columns:\n",
    "    splitters.apply_split_indexes(\n",
    "        sampl_df,\n",
    "        split_type=\"scaffold\",\n",
    "        split_column=\"smiles\",\n",
    "        split_target=\"80-10-10\")\n",
    "    sampl_df.to_csv('SAMPL.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a9f3dba-985f-4e10-b6c1-83a48c0db72a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iupac</th>\n",
       "      <th>smiles</th>\n",
       "      <th>expt</th>\n",
       "      <th>calc</th>\n",
       "      <th>step</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4-methoxy-N,N-dimethyl-benzamide</td>\n",
       "      <td>CN(C)C(=O)c1ccc(cc1)OC</td>\n",
       "      <td>-11.01</td>\n",
       "      <td>-9.625</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>methanesulfonyl chloride</td>\n",
       "      <td>CS(=O)(=O)Cl</td>\n",
       "      <td>-4.87</td>\n",
       "      <td>-6.219</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3-methylbut-1-ene</td>\n",
       "      <td>CC(C)C=C</td>\n",
       "      <td>1.83</td>\n",
       "      <td>2.452</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2-ethylpyrazine</td>\n",
       "      <td>CCc1cnccn1</td>\n",
       "      <td>-5.45</td>\n",
       "      <td>-5.809</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>heptan-1-ol</td>\n",
       "      <td>CCCCCCCO</td>\n",
       "      <td>-4.21</td>\n",
       "      <td>-2.917</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>637</th>\n",
       "      <td>methyl octanoate</td>\n",
       "      <td>CCCCCCCC(=O)OC</td>\n",
       "      <td>-2.04</td>\n",
       "      <td>-3.035</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>638</th>\n",
       "      <td>pyrrolidine</td>\n",
       "      <td>C1CCNC1</td>\n",
       "      <td>-5.48</td>\n",
       "      <td>-4.278</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>639</th>\n",
       "      <td>4-hydroxybenzaldehyde</td>\n",
       "      <td>c1cc(ccc1C=O)O</td>\n",
       "      <td>-8.83</td>\n",
       "      <td>-10.050</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>640</th>\n",
       "      <td>1-chloroheptane</td>\n",
       "      <td>CCCCCCCCl</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1.467</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>641</th>\n",
       "      <td>1,4-dioxane</td>\n",
       "      <td>C1COCCO1</td>\n",
       "      <td>-5.06</td>\n",
       "      <td>-4.269</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>642 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                iupac                  smiles   expt    calc  \\\n",
       "0    4-methoxy-N,N-dimethyl-benzamide  CN(C)C(=O)c1ccc(cc1)OC -11.01  -9.625   \n",
       "1            methanesulfonyl chloride            CS(=O)(=O)Cl  -4.87  -6.219   \n",
       "2                   3-methylbut-1-ene                CC(C)C=C   1.83   2.452   \n",
       "3                     2-ethylpyrazine              CCc1cnccn1  -5.45  -5.809   \n",
       "4                         heptan-1-ol                CCCCCCCO  -4.21  -2.917   \n",
       "..                                ...                     ...    ...     ...   \n",
       "637                  methyl octanoate          CCCCCCCC(=O)OC  -2.04  -3.035   \n",
       "638                       pyrrolidine                 C1CCNC1  -5.48  -4.278   \n",
       "639             4-hydroxybenzaldehyde          c1cc(ccc1C=O)O  -8.83 -10.050   \n",
       "640                   1-chloroheptane               CCCCCCCCl   0.29   1.467   \n",
       "641                       1,4-dioxane                C1COCCO1  -5.06  -4.269   \n",
       "\n",
       "     step  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       3  \n",
       "4       1  \n",
       "..    ...  \n",
       "637     1  \n",
       "638     3  \n",
       "639     1  \n",
       "640     1  \n",
       "641     3  \n",
       "\n",
       "[642 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampl_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67da0ef8-3f10-45f7-b16a-878d2b35a683",
   "metadata": {},
   "source": [
    "## Config Classes\n",
    "\n",
    "First we need to create the interface to interact with sklearn classes and molfeat transforms.\n",
    "\n",
    "To keep the same concepts from other parts of the app, we have 2 kinds of classes:\n",
    "\n",
    "- `ConstructorArgs` classes: describe the arguments given to a class through it's constructor\n",
    "- `Config` classes: describe the interaction with the class; `constructor_args` works as above explained, and `fit_args` models the arguments passed to the ML model class during fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8fc2293d-0023-466e-8001-cbdfe4a4bad5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetConfig(name='Test', target_columns=[ColumnConfig(name='activity', data_type=CategoricalDataType(domain_kind='categorical', classes={'CI': 0, 'CM': 1, 'CA': 2}))], feature_columns=[ColumnConfig(name='smiles', data_type=SmileDataType(domain_kind='smiles'))], featurizers=[], transforms=[FPVecFilteredTransformerConfig(name='MolFPFeaturizer', constructor_args=FPVecFilteredTransformerConstructorArgs(del_invariant=False, length=512), forward_args={'X': '$smiles'}, type='molfeat.trans.fp.FPVecFilteredTransformer')])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "class CamelCaseModel(BaseModel):\n",
    "    \"\"\"\n",
    "    Subclass this class to work with camel case serialization of the model.\n",
    "    \"\"\"\n",
    "    class Config:\n",
    "        alias_generator = camel.case\n",
    "        allow_population_by_field_name = True\n",
    "        allow_population_by_alias = True\n",
    "        underscore_attrs_are_private = True\n",
    "\n",
    "class CreateFromType:\n",
    "    \"\"\"\n",
    "    Adds a method to instantiate a class from it's class path (type) and constructor_args.\n",
    "    \n",
    "    Attributes:\n",
    "        type (str): The class path of the class that will be instantiated.\n",
    "        constructor_args (BaseModel): The constructor arguments passed to the class.\n",
    "    \"\"\"\n",
    "    type: str\n",
    "    constructor_args:  Union[None, BaseModel] = None\n",
    "    \n",
    "    def create(self):\n",
    "        class_ = get_class_from_path_string(self.type)\n",
    "        if self.constructor_args:\n",
    "            return class_(**self.constructor_args.dict())\n",
    "        return class_()\n",
    "\n",
    "class FPVecFilteredTransformerConstructorArgs(BaseModel):\n",
    "    \"\"\"\n",
    "    Models the constructor arguments of a FPVecFilteredTransformer.\n",
    "    \"\"\"\n",
    "    del_invariant: bool = False\n",
    "    length: int = 512\n",
    "    \n",
    "    \n",
    "    \n",
    "class FPVecFilteredTransformerConfig(CamelCaseModel, CreateFromType):\n",
    "    \"\"\"\n",
    "    Models the usage of FPVecFilteredTransformer. \n",
    "    \"\"\"\n",
    "    name: str\n",
    "    constructor_args: FPVecFilteredTransformerConstructorArgs = FPVecFilteredTransformerConstructorArgs()\n",
    "    type = 'molfeat.trans.fp.FPVecFilteredTransformer'\n",
    "    forward_args: dict\n",
    "    \n",
    "    \n",
    "hiv_dataset_config = DatasetConfigBuilder('Test').with_features(\n",
    "    smiles=data_types.SmileDataType(),\n",
    ").with_targets(\n",
    "    activity=data_types.CategoricalDataType(classes={'CI': 0, 'CM': 1, 'CA': 2})\n",
    ").add_transforms(FPVecFilteredTransformerConfig(name=\"MolFPFeaturizer\", forward_args={\n",
    "    'X': '$smiles',\n",
    "})).build()\n",
    "\n",
    "\n",
    "hiv_dataset_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "85537590-439e-49e4-8249-ea5106ac01fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class KNeighborsRegressorConstructorArgs(BaseModel):\n",
    "    n_neighbors: int = 5\n",
    "    algorithm: Literal['kd_tree'] = 'kd__tree'\n",
    "\n",
    "class KNeighborsRegressorConfig(CamelCaseModel, CreateFromType):\n",
    "    name: str\n",
    "    type: Literal['sklearn.neighbors.KNeighborsRegressor'] = 'sklearn.neighbors.KNeighborstRegressor'\n",
    "    constructor_args: KNeighborsRegressorConstructorArgs\n",
    "    fit_args: Dict[str, str]\n",
    "    \n",
    "    \n",
    "class RandomForestRegressorConstructorArgs(BaseModel):\n",
    "    n_estimators: int = 50\n",
    "    max_depth: Union[None, int] = None\n",
    "    min_samples_split: Union[float, int] = 2\n",
    "    min_samples_leaf: Union[float, int] = 1\n",
    "    min_weight_fraction_leaf: float = .0\n",
    "    max_features: Union[None, Literal['sqrt', 'log2']] = 1.\n",
    "    max_leaf_nodes: Union[None, int] = None\n",
    "    min_impurity_decrease: float = .0\n",
    "    bootstrap: bool = True\n",
    "    oob_score: bool = False\n",
    "    n_jobs: Union[int, None] = None\n",
    "    ccp_alpha: float = .0\n",
    "    max_samples: Union[None, int, float] = None\n",
    "\n",
    "class RandomForestRegressorConfig(CamelCaseModel, CreateFromType):\n",
    "    type: Literal['sklearn.ensemble.RandomForestRegressor'] = 'sklearn.ensemble.RandomForestRegressor'\n",
    "    constructor_args: RandomForestRegressorConstructorArgs = RandomForestRegressorConstructorArgs()\n",
    "    fit_args: Dict[str, str]\n",
    "\n",
    "class SklearnDatasetConfig(DatasetConfig):\n",
    "    pass\n",
    "    \n",
    "class SklearnModelSchema(CamelCaseModel, YAML_Model):\n",
    "    model: Union[KNeighborsRegressorConfig, RandomForestRegressorConfig]\n",
    "    \n",
    "class SklearnModelSpec(CamelCaseModel, YAML_Model):\n",
    "    framework = 'sklearn'\n",
    "    name: str\n",
    "    dataset: SklearnDatasetConfig\n",
    "    spec: SklearnModelSchema\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342fe9f4-a4fd-473d-8306-f76a59edc991",
   "metadata": {},
   "source": [
    "We also create a class to operate the models with a dataset. Later this class can be improved to log different metrics depending on the model task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8107dc7b-6ce6-4091-8d4f-e6834f67f4b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class SklearnModelFunctions(BaseModelFunctions):\n",
    "    \n",
    "    model: Union[None, sklearn.base.RegressorMixin, sklearn.base.ClassifierMixin]\n",
    "    \n",
    "    def __init__(self, spec: SklearnModelSpec, dataset: pd.DataFrame):\n",
    "        self.spec = spec\n",
    "        self.dataset = dataset\n",
    "    \n",
    "    def _prepare_X_and_y(self, dataset: Union[None, pd.DataFrame]=None, filter_step: Union[None, int] = None, targets=True):\n",
    "        model_config = self.spec.spec\n",
    "        dataset_config = self.spec.dataset\n",
    "        dataset = dataset if dataset is not None else self.dataset\n",
    "        \n",
    "        if filter_step is not None:\n",
    "            dataset = dataset[dataset['step'] == filter_step]\n",
    "        \n",
    "        references = get_references_dict(model_config.model.fit_args)\n",
    "        args = { key: dataset[ref][:] for key, ref in references.items() }\n",
    "        \n",
    "        assert 'X' in args, 'sklearn models take an X argument'\n",
    "        X = np.stack(args['X'].to_numpy())\n",
    "\n",
    "        if targets:\n",
    "            assert 'y' in args, 'sklearn models take an Y argument'\n",
    "            y = args['y'].to_numpy()\n",
    "            return X, y\n",
    "        else:\n",
    "            return X\n",
    "\n",
    "        \n",
    "    def train(self, *, params: BaseModel=None):\n",
    "        model_config = self.spec.spec\n",
    "        dataset_config = self.spec.dataset\n",
    "        self.model = model_config.model.create()\n",
    "        dataset = data.build_columns_numpy(\n",
    "            dataset_config=dataset_config,\n",
    "            df=self.dataset\n",
    "        )\n",
    "        X, y = self._prepare_X_and_y(filter_step=1)\n",
    "        self.model.fit(X, y)\n",
    "        \n",
    "        \n",
    "    def val(self):\n",
    "        X, y = self._prepare_X_and_y(filter_step=2)\n",
    "        if self.model is None:\n",
    "            raise ValueError('sklearn model not trained')\n",
    "        # coefficient of determination\n",
    "        r2 = self.model.score(X, y)\n",
    "        # TODO: get other metrics\n",
    "        \n",
    "        return r2\n",
    "    \n",
    "    def test(self):\n",
    "        X, y = self._prepare_X_and_y(filter_step=3)\n",
    "        if self.model is None:\n",
    "            raise ValueError('sklearn model not trained')\n",
    "        # coefficient of determination\n",
    "        r2 = self.model.score(X, y)\n",
    "        # TODO: get other metrics\n",
    "        \n",
    "        return r2\n",
    "    \n",
    "    def predict(self, X: pd.DataFrame):\n",
    "        model_config = self.spec.spec\n",
    "        dataset_config = self.spec.dataset\n",
    "        dataset = data.build_columns_numpy(\n",
    "            dataset_config=dataset_config,\n",
    "            df=X\n",
    "        )\n",
    "        X = self._prepare_X_and_y(dataset=dataset, targets=False)\n",
    "        return self.model.predict(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "07df65b7-6ed1-4913-a8be-c8b688f5f721",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vilma/.cache/pypoetry/virtualenvs/mariner-r7bqPCYW-py3.9/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Creates a dataset config for SAMPL using DatasetConfigBuilder\n",
    "sampl_dataset_config = DatasetConfigBuilder('SAMPL').with_features(\n",
    "    smiles=data_types.SmileDataType(),\n",
    ").with_targets(\n",
    "    expt=data_types.NumericDataType()\n",
    ").add_transforms(FPVecFilteredTransformerConfig(name=\"MolFPFeaturizer\", forward_args={\n",
    "    'X': '$smiles',\n",
    "})).build()\n",
    "    \n",
    "# Creates a sklearn model config from yaml str\n",
    "rf_regressor_config = SklearnModelSchema.from_yaml_str(\"\"\"\n",
    "model:\n",
    "    type: sklearn.ensemble.RandomForestRegressor\n",
    "    constructorArgs:\n",
    "        n_estimators: 100\n",
    "    fitArgs:\n",
    "        X: $MolFPFeaturizer\n",
    "        y: $expt\n",
    "\"\"\")\n",
    "\n",
    "sampl_regression_config = SklearnModelSpec(\n",
    "    name=\"SAMPL Regressor\",\n",
    "    dataset=sampl_dataset_config,\n",
    "    spec=rf_regressor_config\n",
    ")\n",
    "        \n",
    "\n",
    "sampl_df = pd.read_csv('SAMPL.csv')\n",
    "assert 'step' in sampl_df.columns\n",
    "\n",
    "sklearn_functions = SklearnModelFunctions(\n",
    "    spec=sampl_regression_config,\n",
    "    dataset=sampl_df\n",
    ")\n",
    "sklearn_functions.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a3c1ef9a-eee1-474b-8619-5a2b420b41b6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16270842502078187"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn_functions.val()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b305266-cf98-40e1-b1ff-4309ccd89a4c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.4164011857206136"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn_functions.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eb68f1b2-d0fd-49b7-b777-aa33f76090aa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vilma/github.com/trident-bio/mariner/backend/fleet/utils/data.py:239: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[transform.name] = apply(transform.create(), value)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 271 features, but RandomForestRegressor is expecting 495 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m X \u001b[38;5;241m=\u001b[39m sampl_df[sampl_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstep\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m      2\u001b[0m y \u001b[38;5;241m=\u001b[39m X[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexpt\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m----> 3\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43msklearn_functions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m sns\u001b[38;5;241m.\u001b[39mscatterplot(x\u001b[38;5;241m=\u001b[39my_pred, y\u001b[38;5;241m=\u001b[39my)\n",
      "Cell \u001b[0;32mIn[8], line 71\u001b[0m, in \u001b[0;36mSklearnModelFunctions.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     66\u001b[0m dataset \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mbuild_columns_numpy(\n\u001b[1;32m     67\u001b[0m     dataset_config\u001b[38;5;241m=\u001b[39mdataset_config,\n\u001b[1;32m     68\u001b[0m     df\u001b[38;5;241m=\u001b[39mX\n\u001b[1;32m     69\u001b[0m )\n\u001b[1;32m     70\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_X_and_y(dataset\u001b[38;5;241m=\u001b[39mdataset, targets\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m---> 71\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/mariner-r7bqPCYW-py3.9/lib64/python3.9/site-packages/sklearn/ensemble/_forest.py:981\u001b[0m, in \u001b[0;36mForestRegressor.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    979\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    980\u001b[0m \u001b[38;5;66;03m# Check data\u001b[39;00m\n\u001b[0;32m--> 981\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_X_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    983\u001b[0m \u001b[38;5;66;03m# Assign chunk of trees to jobs\u001b[39;00m\n\u001b[1;32m    984\u001b[0m n_jobs, _, _ \u001b[38;5;241m=\u001b[39m _partition_estimators(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_estimators, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/mariner-r7bqPCYW-py3.9/lib64/python3.9/site-packages/sklearn/ensemble/_forest.py:602\u001b[0m, in \u001b[0;36mBaseForest._validate_X_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    599\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    600\u001b[0m \u001b[38;5;124;03mValidate X whenever one tries to predict, apply, predict_proba.\"\"\"\u001b[39;00m\n\u001b[1;32m    601\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 602\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDTYPE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    603\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m issparse(X) \u001b[38;5;129;01mand\u001b[39;00m (X\u001b[38;5;241m.\u001b[39mindices\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mintc \u001b[38;5;129;01mor\u001b[39;00m X\u001b[38;5;241m.\u001b[39mindptr\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mintc):\n\u001b[1;32m    604\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo support for np.int64 index based sparse matrices\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/mariner-r7bqPCYW-py3.9/lib64/python3.9/site-packages/sklearn/base.py:588\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    585\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m    587\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m--> 588\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_n_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    590\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/mariner-r7bqPCYW-py3.9/lib64/python3.9/site-packages/sklearn/base.py:389\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    386\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    388\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_features \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_:\n\u001b[0;32m--> 389\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    390\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features, but \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    391\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis expecting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features as input.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    392\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: X has 271 features, but RandomForestRegressor is expecting 495 features as input."
     ]
    }
   ],
   "source": [
    "X = sampl_df[sampl_df['step'] == 2]\n",
    "y = X['expt']\n",
    "y_pred = sklearn_functions.predict(X)\n",
    "sns.scatterplot(x=y_pred, y=y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
