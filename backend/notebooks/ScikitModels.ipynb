{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0beb9530-f3f0-464a-a46c-6c5bbb9fc433",
   "metadata": {},
   "source": [
    "## Sci-kit dataset preparation as matrix\n",
    "\n",
    "This notebook shows how to prepare the datasets for sci-kit based models. Sci-kit's API is very consistent, and it should work \"out of the box\" when given numeric (2D) matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bae21c38-91b1-4b10-9147-58a1debfe3a2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -q seaborn molfeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe9ba0df-527c-44d6-befe-1cb112946cca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import Literal, Union, Dict, List\n",
    "\n",
    "import os\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from humps import camel\n",
    "from pydantic import BaseModel\n",
    "import numpy as np\n",
    "import sklearn.base\n",
    "import mlflow.sklearn\n",
    "import mlflow\n",
    "import mlflow.tracking\n",
    "\n",
    "from fleet.base_schemas import BaseModelFunctions\n",
    "from fleet.model_builder.utils import get_references_dict\n",
    "from fleet.dataset_schemas import DatasetConfigBuilder, DatasetConfig\n",
    "from fleet import data_types\n",
    "from fleet.utils import data\n",
    "from fleet.yaml_model import YAML_Model\n",
    "from fleet.model_builder.utils import get_class_from_path_string\n",
    "from fleet.model_builder import splitters\n",
    "from fleet.metrics import Metrics\n",
    "\n",
    "from mariner.core.mlflowapi import log_sklearn_model_and_create_version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "200281ad-bd78-4fe0-b4eb-8a8552562a5f",
   "metadata": {},
   "source": [
    "### Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3eaec021-c125-4878-92a6-39909754ef5f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-06-20 20:51:43--  https://deepchemdata.s3-us-west-1.amazonaws.com/datasets/HIV.csv\n",
      "Resolving deepchemdata.s3-us-west-1.amazonaws.com (deepchemdata.s3-us-west-1.amazonaws.com)... 3.5.162.161\n",
      "Connecting to deepchemdata.s3-us-west-1.amazonaws.com (deepchemdata.s3-us-west-1.amazonaws.com)|3.5.162.161|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 2193844 (2.1M) [text/csv]\n",
      "Saving to: ‘HIV.csv’\n",
      "\n",
      "HIV.csv             100%[===================>]   2.09M   573KB/s    in 3.7s    \n",
      "\n",
      "2023-06-20 20:51:48 (573 KB/s) - ‘HIV.csv’ saved [2193844/2193844]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! [ ! -f HIV.csv ] && wget https://deepchemdata.s3-us-west-1.amazonaws.com/datasets/HIV.csv\n",
    "! [ ! -f SAMPL.csv ] && wget https://deepchemdata.s3-us-west-1.amazonaws.com/datasets/SAMPL.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b22f97f8-39b8-4f54-abce-cf717eb3baa1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[20:51:56] WARNING: not removing hydrogen atom without neighbors\n",
      "[20:51:56] WARNING: not removing hydrogen atom without neighbors\n"
     ]
    }
   ],
   "source": [
    "hiv_df = pd.read_csv('HIV.csv')\n",
    "sampl_df = pd.read_csv('SAMPL.csv')\n",
    "\n",
    "if 'step' not in hiv_df.columns:\n",
    "    splitters.apply_split_indexes(\n",
    "        hiv_df,\n",
    "        split_type=\"scaffold\",\n",
    "        split_column=\"smiles\",\n",
    "        split_target=\"80-10-10\")\n",
    "    hiv_df.to_csv('HIV.csv', index=False)\n",
    "\n",
    "if 'step' not in sampl_df.columns:\n",
    "    splitters.apply_split_indexes(\n",
    "        sampl_df,\n",
    "        split_type=\"scaffold\",\n",
    "        split_column=\"smiles\",\n",
    "        split_target=\"80-10-10\")\n",
    "    sampl_df.to_csv('SAMPL.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a9f3dba-985f-4e10-b6c1-83a48c0db72a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iupac</th>\n",
       "      <th>smiles</th>\n",
       "      <th>expt</th>\n",
       "      <th>calc</th>\n",
       "      <th>step</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4-methoxy-N,N-dimethyl-benzamide</td>\n",
       "      <td>CN(C)C(=O)c1ccc(cc1)OC</td>\n",
       "      <td>-11.01</td>\n",
       "      <td>-9.625</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>methanesulfonyl chloride</td>\n",
       "      <td>CS(=O)(=O)Cl</td>\n",
       "      <td>-4.87</td>\n",
       "      <td>-6.219</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3-methylbut-1-ene</td>\n",
       "      <td>CC(C)C=C</td>\n",
       "      <td>1.83</td>\n",
       "      <td>2.452</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2-ethylpyrazine</td>\n",
       "      <td>CCc1cnccn1</td>\n",
       "      <td>-5.45</td>\n",
       "      <td>-5.809</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>heptan-1-ol</td>\n",
       "      <td>CCCCCCCO</td>\n",
       "      <td>-4.21</td>\n",
       "      <td>-2.917</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>637</th>\n",
       "      <td>methyl octanoate</td>\n",
       "      <td>CCCCCCCC(=O)OC</td>\n",
       "      <td>-2.04</td>\n",
       "      <td>-3.035</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>638</th>\n",
       "      <td>pyrrolidine</td>\n",
       "      <td>C1CCNC1</td>\n",
       "      <td>-5.48</td>\n",
       "      <td>-4.278</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>639</th>\n",
       "      <td>4-hydroxybenzaldehyde</td>\n",
       "      <td>c1cc(ccc1C=O)O</td>\n",
       "      <td>-8.83</td>\n",
       "      <td>-10.050</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>640</th>\n",
       "      <td>1-chloroheptane</td>\n",
       "      <td>CCCCCCCCl</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1.467</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>641</th>\n",
       "      <td>1,4-dioxane</td>\n",
       "      <td>C1COCCO1</td>\n",
       "      <td>-5.06</td>\n",
       "      <td>-4.269</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>642 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                iupac                  smiles   expt    calc  \\\n",
       "0    4-methoxy-N,N-dimethyl-benzamide  CN(C)C(=O)c1ccc(cc1)OC -11.01  -9.625   \n",
       "1            methanesulfonyl chloride            CS(=O)(=O)Cl  -4.87  -6.219   \n",
       "2                   3-methylbut-1-ene                CC(C)C=C   1.83   2.452   \n",
       "3                     2-ethylpyrazine              CCc1cnccn1  -5.45  -5.809   \n",
       "4                         heptan-1-ol                CCCCCCCO  -4.21  -2.917   \n",
       "..                                ...                     ...    ...     ...   \n",
       "637                  methyl octanoate          CCCCCCCC(=O)OC  -2.04  -3.035   \n",
       "638                       pyrrolidine                 C1CCNC1  -5.48  -4.278   \n",
       "639             4-hydroxybenzaldehyde          c1cc(ccc1C=O)O  -8.83 -10.050   \n",
       "640                   1-chloroheptane               CCCCCCCCl   0.29   1.467   \n",
       "641                       1,4-dioxane                C1COCCO1  -5.06  -4.269   \n",
       "\n",
       "     step  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       3  \n",
       "4       1  \n",
       "..    ...  \n",
       "637     1  \n",
       "638     3  \n",
       "639     1  \n",
       "640     1  \n",
       "641     3  \n",
       "\n",
       "[642 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampl_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67da0ef8-3f10-45f7-b16a-878d2b35a683",
   "metadata": {},
   "source": [
    "## Config Classes\n",
    "\n",
    "First we need to create the interface to interact with sklearn classes and molfeat transforms.\n",
    "\n",
    "To keep the same concepts from other parts of the app, we have 2 kinds of classes:\n",
    "\n",
    "- `ConstructorArgs` classes: describe the arguments given to a class through it's constructor\n",
    "- `Config` classes: describe the interaction with the class; `constructor_args` works as above explained, and `fit_args` models the arguments passed to the ML model class during fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8fc2293d-0023-466e-8001-cbdfe4a4bad5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetConfig(name='Test', target_columns=[ColumnConfig(name='activity', data_type=CategoricalDataType(domain_kind='categorical', classes={'CI': 0, 'CM': 1, 'CA': 2}))], feature_columns=[ColumnConfig(name='smiles', data_type=SmileDataType(domain_kind='smiles'))], featurizers=[], transforms=[FPVecFilteredTransformerConfig(name='MolFPFeaturizer', constructor_args=FPVecFilteredTransformerConstructorArgs(del_invariant=None, length=None), forward_args={'X': '$smiles'}, type='molfeat.trans.fp.FPVecFilteredTransformer')])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "class CamelCaseModel(BaseModel):\n",
    "    \"\"\"\n",
    "    Subclass this class to work with camel case serialization of the model.\n",
    "    \"\"\"\n",
    "    class Config:\n",
    "        alias_generator = camel.case\n",
    "        allow_population_by_field_name = True\n",
    "        allow_population_by_alias = True\n",
    "        underscore_attrs_are_private = True\n",
    "\n",
    "class CreateFromType:\n",
    "    \"\"\"\n",
    "    Adds a method to instantiate a class from it's class path (type) and constructor_args.\n",
    "    \n",
    "    Attributes:\n",
    "        type (str): The class path of the class that will be instantiated.\n",
    "        constructor_args (BaseModel): The constructor arguments passed to the class.\n",
    "    \"\"\"\n",
    "    type: str\n",
    "    constructor_args:  Union[None, BaseModel] = None\n",
    "    \n",
    "    def create(self):\n",
    "        class_ = get_class_from_path_string(self.type)\n",
    "        if self.constructor_args:\n",
    "            return class_(**self.constructor_args.dict())\n",
    "        return class_()\n",
    "\n",
    "\n",
    "class FPVecFilteredTransformerConstructorArgs(BaseModel):\n",
    "    \"\"\"\n",
    "    Models the constructor arguments of a FPVecFilteredTransformer.\n",
    "    \"\"\"\n",
    "    del_invariant: bool = None\n",
    "    length: int = None\n",
    "\n",
    "\n",
    "class FPVecFilteredTransformerConfig(CamelCaseModel, CreateFromType):\n",
    "    \"\"\"\n",
    "    Models the usage of FPVecFilteredTransformer. \n",
    "    \"\"\"\n",
    "    name: str\n",
    "    constructor_args: FPVecFilteredTransformerConstructorArgs = FPVecFilteredTransformerConstructorArgs()\n",
    "    type = 'molfeat.trans.fp.FPVecFilteredTransformer'\n",
    "    forward_args: dict\n",
    "    \n",
    "    \n",
    "hiv_dataset_config = DatasetConfigBuilder('Test').with_features(\n",
    "    smiles=data_types.SmileDataType(),\n",
    ").with_targets(\n",
    "    activity=data_types.CategoricalDataType(classes={'CI': 0, 'CM': 1, 'CA': 2})\n",
    ").add_transforms(FPVecFilteredTransformerConfig(name=\"MolFPFeaturizer\", forward_args={\n",
    "    'X': '$smiles',\n",
    "})).build()\n",
    "\n",
    "\n",
    "hiv_dataset_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "85537590-439e-49e4-8249-ea5106ac01fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "TaskType = Literal['regressor', 'multiclass', 'multilabel']\n",
    "\n",
    "class KNeighborsRegressorConstructorArgs(BaseModel):\n",
    "    n_neighbors: int = 5\n",
    "    algorithm: Literal['kd_tree'] = 'kd_tree'\n",
    "\n",
    "\n",
    "class KNeighborsRegressorConfig(CamelCaseModel, CreateFromType):\n",
    "    type: Literal['sklearn.neighbors.KNeighborsRegressor'] = 'sklearn.neighbors.KNeighborstRegressor'\n",
    "    constructor_args: KNeighborsRegressorConstructorArgs = KNeighborsRegressorConstructorArgs()\n",
    "    fit_args: Dict[str, str]\n",
    "    task_type: List[TaskType] = [ 'regressor' ]\n",
    "    \n",
    "\n",
    "class RandomForestRegressorConstructorArgs(BaseModel):\n",
    "    n_estimators: int = 50\n",
    "    max_depth: Union[None, int] = None\n",
    "    min_samples_split: Union[float, int] = 2\n",
    "    min_samples_leaf: Union[float, int] = 1\n",
    "    min_weight_fraction_leaf: float = .0\n",
    "    max_features: Union[None, Literal['sqrt', 'log2']] = 1.\n",
    "    max_leaf_nodes: Union[None, int] = None\n",
    "    min_impurity_decrease: float = .0\n",
    "    bootstrap: bool = True\n",
    "    oob_score: bool = False\n",
    "    n_jobs: Union[int, None] = None\n",
    "    ccp_alpha: float = .0\n",
    "    max_samples: Union[None, int, float] = None\n",
    "\n",
    "\n",
    "class RandomForestRegressorConfig(CamelCaseModel, CreateFromType):\n",
    "    type: Literal['sklearn.ensemble.RandomForestRegressor'] = 'sklearn.ensemble.RandomForestRegressor'\n",
    "    task_type: List[TaskType] = [ 'regressor' ]\n",
    "    constructor_args: RandomForestRegressorConstructorArgs = RandomForestRegressorConstructorArgs()\n",
    "    fit_args: Dict[str, str]\n",
    "\n",
    "\n",
    "class SklearnDatasetConfig(DatasetConfig):\n",
    "    pass\n",
    "\n",
    "\n",
    "class SklearnModelSchema(CamelCaseModel, YAML_Model):\n",
    "    model: Union[KNeighborsRegressorConfig, RandomForestRegressorConfig]\n",
    "\n",
    "\n",
    "class SklearnModelSpec(CamelCaseModel, YAML_Model):\n",
    "    framework = 'sklearn'\n",
    "    name: str\n",
    "    dataset: SklearnDatasetConfig\n",
    "    spec: SklearnModelSchema\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342fe9f4-a4fd-473d-8306-f76a59edc991",
   "metadata": {},
   "source": [
    "We also create a class to operate the models with a dataset. Later this class can be improved to log different metrics depending on the model task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8107dc7b-6ce6-4091-8d4f-e6834f67f4b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class SklearnModelFunctions(BaseModelFunctions):\n",
    "    \n",
    "    model: Union[None, sklearn.base.RegressorMixin, sklearn.base.ClassifierMixin]\n",
    "    \n",
    "    def __init__(self, spec: SklearnModelSpec, dataset: pd.DataFrame):\n",
    "        self.spec = spec\n",
    "        self.dataset = dataset\n",
    "        self.metrics = Metrics(model_type=\"regression\", return_type=\"float\")\n",
    "    \n",
    "    def _prepare_X_and_y(self, dataset: Union[None, pd.DataFrame]=None, filter_step: Union[None, int] = None, targets=True):\n",
    "        model_config = self.spec.spec\n",
    "        dataset_config = self.spec.dataset\n",
    "        dataset = dataset if dataset is not None else self.dataset\n",
    "        \n",
    "        if filter_step is not None:\n",
    "            dataset = dataset[dataset['step'] == filter_step]\n",
    "        \n",
    "        references = get_references_dict(model_config.model.fit_args)\n",
    "        args = { key: dataset[ref][:] for key, ref in references.items() }\n",
    "        \n",
    "        assert 'X' in args, 'sklearn models take an X argument'\n",
    "        X = np.stack(args['X'].to_numpy())\n",
    "\n",
    "        if targets:\n",
    "            assert 'y' in args, 'sklearn models take an Y argument'\n",
    "            y = args['y'].to_numpy()\n",
    "            return X, y\n",
    "        else:\n",
    "            return X\n",
    "\n",
    "        \n",
    "    def train(self, *, params: BaseModel=None):\n",
    "        model_config = self.spec.spec\n",
    "        dataset_config = self.spec.dataset\n",
    "        self.model = model_config.model.create()\n",
    "        dataset = data.build_columns_numpy(\n",
    "            dataset_config=dataset_config,\n",
    "            df=self.dataset\n",
    "        )\n",
    "        if hasattr(model_config.model, 'constructor_args'):\n",
    "            mlflow.log_params(model_config.model.constructor_args.dict())\n",
    "        X, y = self._prepare_X_and_y(filter_step=1)\n",
    "        self.model.fit(X, y)\n",
    "        y_pred = self.model.predict(X)\n",
    "        metrics_dict = self.metrics.get_training_metrics(y_pred, y)\n",
    "        mlflow.log_metrics(metrics_dict)\n",
    "        return metrics_dict\n",
    "\n",
    "    def val(self):\n",
    "        X, y = self._prepare_X_and_y(filter_step=2)\n",
    "        if self.model is None:\n",
    "            raise ValueError('sklearn model not trained')\n",
    "        y_pred = self.model.predict(X)\n",
    "        metrics_dict = self.metrics.get_validation_metrics(y_pred, y)\n",
    "        mlflow.log_metrics(metrics_dict)\n",
    "        return metrics_dict\n",
    "    \n",
    "    def test(self):\n",
    "        X, y = self._prepare_X_and_y(filter_step=3)\n",
    "        if self.model is None:\n",
    "            raise ValueError('sklearn model not trained')\n",
    "        y_pred = self.model.predict(X)\n",
    "        metrics_dict = self.metrics.get_test_metrics(y_pred, y)\n",
    "        mlflow.log_metrics(metrics_dict)\n",
    "        return metrics_dict\n",
    "    \n",
    "    def predict(self, X: pd.DataFrame):\n",
    "        model_config = self.spec.spec\n",
    "        dataset_config = self.spec.dataset\n",
    "        dataset = data.build_columns_numpy(\n",
    "            dataset_config=dataset_config,\n",
    "            df=X\n",
    "        )\n",
    "        X = self._prepare_X_and_y(dataset=dataset, targets=False)\n",
    "        return self.model.predict(X)\n",
    "    \n",
    "    def log_model(\n",
    "        self,\n",
    "        model_name: Union[None, str] = None,\n",
    "        version_description: Union[None, str] = None,\n",
    "        run_id: Union[None, str] = None\n",
    "    ):\n",
    "        return log_sklearn_model_and_create_version(\n",
    "            self.model,\n",
    "            model_name=model_name,\n",
    "            version_description=version_description,\n",
    "            run_id=run_id\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "07df65b7-6ed1-4913-a8be-c8b688f5f721",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vilma/.cache/pypoetry/virtualenvs/mariner-r7bqPCYW-py3.9/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/vilma/.cache/pypoetry/virtualenvs/mariner-r7bqPCYW-py3.9/lib/python3.9/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n",
      "2023/06/20 20:53:25 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation.                     Model name: SAMPL Regressor, version 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<ModelVersion: creation_timestamp=1687305205420, current_stage='None', description=None, last_updated_timestamp=1687305205420, name='SAMPL Regressor', run_id='c0d879d600f147599c41376c69847dc8', run_link=None, source='file:///home/vilma/github.com/trident-bio/mariner/backend/notebooks/mlruns/0/c0d879d600f147599c41376c69847dc8/artifacts/model', status='READY', status_message=None, tags={}, user_id=None, version=1>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/06/20 20:53:27 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation.                     Model name: SAMPL Regressor, version 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<ModelVersion: creation_timestamp=1687305207230, current_stage='None', description=None, last_updated_timestamp=1687305207230, name='SAMPL Regressor', run_id='c749fc28016948c3986405184329fa64', run_link=None, source='file:///home/vilma/github.com/trident-bio/mariner/backend/notebooks/mlruns/0/c749fc28016948c3986405184329fa64/artifacts/model', status='READY', status_message=None, tags={}, user_id=None, version=2>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>train/mse</th>\n",
       "      <th>train/mae</th>\n",
       "      <th>train/ev</th>\n",
       "      <th>train/mape</th>\n",
       "      <th>train/R2</th>\n",
       "      <th>train/pearson</th>\n",
       "      <th>val/mse</th>\n",
       "      <th>val/mae</th>\n",
       "      <th>val/ev</th>\n",
       "      <th>val/mape</th>\n",
       "      <th>val/R2</th>\n",
       "      <th>val/pearson</th>\n",
       "      <th>test/mse</th>\n",
       "      <th>test/mae</th>\n",
       "      <th>test/ev</th>\n",
       "      <th>test/mape</th>\n",
       "      <th>test/R2</th>\n",
       "      <th>test/pearson</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rf</td>\n",
       "      <td>0.473269</td>\n",
       "      <td>0.395354</td>\n",
       "      <td>0.956822</td>\n",
       "      <td>528.410217</td>\n",
       "      <td>0.955943</td>\n",
       "      <td>0.982282</td>\n",
       "      <td>32.769363</td>\n",
       "      <td>3.614880</td>\n",
       "      <td>0.374197</td>\n",
       "      <td>0.654538</td>\n",
       "      <td>0.113386</td>\n",
       "      <td>0.659518</td>\n",
       "      <td>19.339958</td>\n",
       "      <td>3.414269</td>\n",
       "      <td>0.266169</td>\n",
       "      <td>0.576622</td>\n",
       "      <td>-0.463237</td>\n",
       "      <td>0.520069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>knn</td>\n",
       "      <td>3.327777</td>\n",
       "      <td>1.317216</td>\n",
       "      <td>0.735269</td>\n",
       "      <td>977.110596</td>\n",
       "      <td>0.690215</td>\n",
       "      <td>0.866206</td>\n",
       "      <td>48.096344</td>\n",
       "      <td>4.645344</td>\n",
       "      <td>0.130169</td>\n",
       "      <td>0.998109</td>\n",
       "      <td>-0.301304</td>\n",
       "      <td>0.364089</td>\n",
       "      <td>29.303942</td>\n",
       "      <td>4.282523</td>\n",
       "      <td>-0.010579</td>\n",
       "      <td>0.678985</td>\n",
       "      <td>-1.217100</td>\n",
       "      <td>0.189845</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   key  train/mse  train/mae  train/ev  train/mape  train/R2  train/pearson  \\\n",
       "0   rf   0.473269   0.395354  0.956822  528.410217  0.955943       0.982282   \n",
       "1  knn   3.327777   1.317216  0.735269  977.110596  0.690215       0.866206   \n",
       "\n",
       "     val/mse   val/mae    val/ev  val/mape    val/R2  val/pearson   test/mse  \\\n",
       "0  32.769363  3.614880  0.374197  0.654538  0.113386     0.659518  19.339958   \n",
       "1  48.096344  4.645344  0.130169  0.998109 -0.301304     0.364089  29.303942   \n",
       "\n",
       "   test/mae   test/ev  test/mape   test/R2  test/pearson  \n",
       "0  3.414269  0.266169   0.576622 -0.463237      0.520069  \n",
       "1  4.282523 -0.010579   0.678985 -1.217100      0.189845  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Creates a dataset config for SAMPL using DatasetConfigBuilder\n",
    "sampl_dataset_config = DatasetConfigBuilder('SAMPL').with_features(\n",
    "    smiles=data_types.SmileDataType(),\n",
    ").with_targets(\n",
    "    expt=data_types.NumericDataType()\n",
    ").add_transforms(FPVecFilteredTransformerConfig(name=\"MolFPFeaturizer\", forward_args={\n",
    "    'X': '$smiles',\n",
    "})).build()\n",
    "\n",
    "sampl_df = pd.read_csv('SAMPL.csv')\n",
    "assert 'step' in sampl_df.columns\n",
    "\n",
    "\n",
    "rf_model_yaml = \"\"\"\n",
    "model:\n",
    "    type: sklearn.ensemble.RandomForestRegressor\n",
    "    constructorArgs:\n",
    "        n_estimators: 100\n",
    "    fitArgs:\n",
    "        X: $MolFPFeaturizer\n",
    "        y: $expt\n",
    "\"\"\"\n",
    "\n",
    "knn_model_yaml = \"\"\"\n",
    "model:\n",
    "    type: sklearn.neighbors.KNeighborsRegressor\n",
    "    fitArgs:\n",
    "        X: $MolFPFeaturizer\n",
    "        y: $expt\n",
    "\"\"\"\n",
    "\n",
    "# Creating the mlflow registeredd model\n",
    "client = mlflow.tracking.MlflowClient(\n",
    "    tracking_uri=os.getenv('MLFLOW_TRACKING_URI'),\n",
    ")\n",
    "try:\n",
    "    reg_model = client.get_registered_model('SAMPL Regressor')\n",
    "except:\n",
    "    reg_model = client.create_registered_model('SAMPL Regressor')\n",
    "\n",
    "\n",
    "# Creates a sklearn model config from yaml str\n",
    "model_functions = {\n",
    "    'rf': SklearnModelFunctions(\n",
    "            dataset=sampl_df,\n",
    "            spec=SklearnModelSpec(\n",
    "                name=\"SAMPL Regressor - Random Forest\",\n",
    "                dataset=sampl_dataset_config,\n",
    "                spec=SklearnModelSchema.from_yaml_str(rf_model_yaml),\n",
    "        )),\n",
    "    'knn': SklearnModelFunctions(\n",
    "            dataset=sampl_df,\n",
    "            spec=SklearnModelSpec(\n",
    "                name=\"SAMPL Regressor - KNN\",\n",
    "                dataset=sampl_dataset_config,\n",
    "                spec=SklearnModelSchema.from_yaml_str(knn_model_yaml),\n",
    "        )),\n",
    "}\n",
    "\n",
    "results = []\n",
    "for key, model in model_functions.items():\n",
    "    with mlflow.start_run(nested=True) as run:\n",
    "        train_metrics = model.train()\n",
    "        val_metrics = model.val()\n",
    "        test_metrics = model.test()\n",
    "        mlflow_model_version = model.log_model(\n",
    "            model_name=f\"SAMPL Regressor\",\n",
    "            run_id=run.info.run_id)\n",
    "        item = {'key': key}\n",
    "        for metrickey, metricvalue in (\n",
    "            train_metrics | val_metrics | test_metrics\n",
    "        ).items():\n",
    "            item[metrickey] = metricvalue\n",
    "        results.append(item)\n",
    "pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ecab5127-c065-43a1-b6a4-efe8e988fd4a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vilma/github.com/trident-bio/mariner/backend/fleet/utils/data.py:466: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[transform.name] = apply(transform.create(), value)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 357 features, but RandomForestRegressor is expecting 1224 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, model \u001b[38;5;129;01min\u001b[39;00m model_functions\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m      3\u001b[0m     X \u001b[38;5;241m=\u001b[39m sampl_df[sampl_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstep\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m]\n\u001b[0;32m----> 4\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     sns\u001b[38;5;241m.\u001b[39mscatterplot(x\u001b[38;5;241m=\u001b[39my_pred, y\u001b[38;5;241m=\u001b[39my)\n",
      "Cell \u001b[0;32mIn[8], line 75\u001b[0m, in \u001b[0;36mSklearnModelFunctions.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     70\u001b[0m dataset \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mbuild_columns_numpy(\n\u001b[1;32m     71\u001b[0m     dataset_config\u001b[38;5;241m=\u001b[39mdataset_config,\n\u001b[1;32m     72\u001b[0m     df\u001b[38;5;241m=\u001b[39mX\n\u001b[1;32m     73\u001b[0m )\n\u001b[1;32m     74\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_X_and_y(dataset\u001b[38;5;241m=\u001b[39mdataset, targets\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m---> 75\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/mariner-r7bqPCYW-py3.9/lib64/python3.9/site-packages/sklearn/ensemble/_forest.py:981\u001b[0m, in \u001b[0;36mForestRegressor.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    979\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    980\u001b[0m \u001b[38;5;66;03m# Check data\u001b[39;00m\n\u001b[0;32m--> 981\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_X_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    983\u001b[0m \u001b[38;5;66;03m# Assign chunk of trees to jobs\u001b[39;00m\n\u001b[1;32m    984\u001b[0m n_jobs, _, _ \u001b[38;5;241m=\u001b[39m _partition_estimators(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_estimators, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/mariner-r7bqPCYW-py3.9/lib64/python3.9/site-packages/sklearn/ensemble/_forest.py:602\u001b[0m, in \u001b[0;36mBaseForest._validate_X_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    599\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    600\u001b[0m \u001b[38;5;124;03mValidate X whenever one tries to predict, apply, predict_proba.\"\"\"\u001b[39;00m\n\u001b[1;32m    601\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 602\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDTYPE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    603\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m issparse(X) \u001b[38;5;129;01mand\u001b[39;00m (X\u001b[38;5;241m.\u001b[39mindices\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mintc \u001b[38;5;129;01mor\u001b[39;00m X\u001b[38;5;241m.\u001b[39mindptr\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mintc):\n\u001b[1;32m    604\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo support for np.int64 index based sparse matrices\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/mariner-r7bqPCYW-py3.9/lib64/python3.9/site-packages/sklearn/base.py:588\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    585\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m    587\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m--> 588\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_n_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    590\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/mariner-r7bqPCYW-py3.9/lib64/python3.9/site-packages/sklearn/base.py:389\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    386\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    388\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_features \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_:\n\u001b[0;32m--> 389\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    390\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features, but \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    391\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis expecting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features as input.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    392\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: X has 357 features, but RandomForestRegressor is expecting 1224 features as input."
     ]
    }
   ],
   "source": [
    "# Test prediction of models\n",
    "for key, model in model_functions.items():\n",
    "    X = sampl_df[sampl_df['step'] == 2]\n",
    "    y_pred = model.predict(X)\n",
    "    sns.scatterplot(x=y_pred, y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc888121-5244-4b66-80f9-bbaf4c66e770",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
