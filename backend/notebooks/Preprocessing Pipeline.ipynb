{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8780715-72aa-4e92-8836-3dbe3a474683",
   "metadata": {},
   "source": [
    "# Preprocessing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b783e2fe-4841-450b-b740-7d0b5ac074db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union, List, Literal, Annotated, Callable, Dict, Any, Tuple\n",
    "\n",
    "from humps import camel\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.preprocessing\n",
    "import sklearn.datasets\n",
    "import torch.nn\n",
    "\n",
    "from fleet.model_builder import splitters\n",
    "from fleet import data_types\n",
    "from fleet.utils.data import dataset_topo_sort, get_default_data_type_featurizer\n",
    "from fleet.yaml_model import YAML_Model\n",
    "from fleet.dataset_schemas import DatasetConfig, ColumnConfig\n",
    "from fleet.model_builder.featurizers import DNASequenceFeaturizer\n",
    "from fleet.model_builder.utils import get_class_from_path_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dc54f931-fcf9-4154-9344-edba86a823a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! [ ! -f SAMPL.csv ] && wget https://deepchemdata.s3-us-west-1.amazonaws.com/datasets/SAMPL.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "58db1504-ad1a-44da-b2ec-1e95aead37b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "iris_df = sklearn.datasets.load_iris(as_frame=True)\n",
    "sampl_df = pd.read_csv('SAMPL.csv')\n",
    "\n",
    "classes = iris_df.target_names\n",
    "def get_class(item):\n",
    "    return classes[item]\n",
    "\n",
    "iris_df.data['sepal length (cm)']\n",
    "iris_df.data['species'] = np.apply_along_axis(get_class, 0, iris_df.target)\n",
    "iris_df = iris_df.data\n",
    "\n",
    "if 'step' not in sampl_df.columns:\n",
    "    splitters.apply_split_indexes(\n",
    "        sampl_df,\n",
    "        split_type=\"scaffold\",\n",
    "        split_column=\"smiles\",\n",
    "        split_target=\"80-10-10\")\n",
    "if 'step' not in iris_df.columns:\n",
    "    splitters.apply_split_indexes(\n",
    "        iris_df,\n",
    "        split_type=\"random\",\n",
    "        split_target=\"60-20-20\")\n",
    "    \n",
    "    sampl_df.to_csv('SAMPL.csv', index=False)\n",
    "\n",
    "# Some utility classes:\n",
    "\n",
    "class CamelCaseModel(BaseModel):\n",
    "    \"\"\"\n",
    "    Subclass this class to work with camel case serialization of the model.\n",
    "    \"\"\"\n",
    "    class Config:\n",
    "        alias_generator = camel.case\n",
    "        allow_population_by_field_name = True\n",
    "        allow_population_by_alias = True\n",
    "        underscore_attrs_are_private = True\n",
    "\n",
    "class CreateFromType(BaseModel):\n",
    "    \"\"\"\n",
    "    Adds a method to instantiate a class from it's class path (type) and constructor_args.\n",
    "    \n",
    "    Attributes:\n",
    "        type (str): The class path of the class that will be instantiated.\n",
    "        constructor_args (BaseModel): The constructor arguments passed to the class.\n",
    "    \"\"\"\n",
    "    type: str\n",
    "    constructor_args:  Union[None, BaseModel]\n",
    "    \n",
    "    def create(self):\n",
    "        class_ = get_class_from_path_string(self.type)\n",
    "        if self.constructor_args:\n",
    "            return class_(**self.constructor_args.dict())\n",
    "        return class_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "580f4c7b-290c-4146-ad40-cb8a003b6a50",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Featurizers\n",
    "\n",
    "class FPVecFilteredTransformerConstructorArgs(BaseModel):\n",
    "    \"\"\"\n",
    "    Models the constructor arguments of a FPVecFilteredTransformer.\n",
    "    \"\"\"\n",
    "    del_invariant: bool = None\n",
    "    length: int = None\n",
    "\n",
    "\n",
    "class FPVecFilteredTransformerConfig(CamelCaseModel, CreateFromType):\n",
    "    \"\"\"\n",
    "    Models the usage of FPVecFilteredTransformer. \n",
    "    \"\"\"\n",
    "    name: str\n",
    "    constructor_args: FPVecFilteredTransformerConstructorArgs = FPVecFilteredTransformerConstructorArgs()\n",
    "    type: Literal['molfeat.trans.fp.FPVecFilteredTransformer'] = 'molfeat.trans.fp.FPVecFilteredTransformer'\n",
    "    forward_args: Union[None, dict] = None\n",
    "    \n",
    "    \n",
    "class DNASequenceFeaturizerConfig(CamelCaseModel):\n",
    "    name: str\n",
    "    type: Literal[\"fleet.model_builder.featurizers.DNASequenceFeaturizer\"] = \"fleet.model_builder.featurizers.DNASequenceFeaturizer\"\n",
    "    forward_args: Union[None, dict] = None\n",
    "\n",
    "Featurizer = Annotated[Union[\n",
    "        FPVecFilteredTransformerConfig,\n",
    "        DNASequenceFeaturizerConfig,\n",
    "    ], Field(discriminator=\"type\")]\n",
    "class FeaturizerConfig(CamelCaseModel):\n",
    "    __root__: Featurizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a3bc5bac-898f-4f73-a2ce-14ba44045fa3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Transforms\n",
    "\n",
    "class LabelEncoderConfig(CreateFromType, CamelCaseModel):\n",
    "    type: Literal['sklearn.preprocessing.LabelEncoder'] = 'sklearn.preprocessing.LabelEncoder'\n",
    "    name: str\n",
    "    forward_args: Dict[str, str]\n",
    "\n",
    "\n",
    "class StandardScalerConstructorArgs(BaseModel):\n",
    "    with_mean: bool = True\n",
    "    with_std: bool = True\n",
    "\n",
    "\n",
    "class StandardScalerConfig(CreateFromType, CamelCaseModel):\n",
    "    type: Literal['sklearn.preprocessing.StandardScaler'] = 'sklearn.preprocessing.StandardScaler'\n",
    "    constructor_args: StandardScalerConstructorArgs = StandardScalerConstructorArgs()\n",
    "    name: str\n",
    "    forward_args: Dict[str, str]\n",
    "\n",
    "Transformer = Annotated[Union[\n",
    "        StandardScalerConfig,\n",
    "        LabelEncoderConfig,\n",
    "    ], Field(discriminator=\"type\")]\n",
    "\n",
    "class TransformConfig(CamelCaseModel):\n",
    "    __root__: Transformer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9f13600c-c055-4bdb-b523-1e00a14c7b78",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>StandardScaler()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TransformConfig.parse_obj({\n",
    "    'name': 'transformer',\n",
    "    'type': 'sklearn.preprocessing.StandardScaler',\n",
    "    'forward_args': {\n",
    "        'X': '$sepal_width'\n",
    "    }\n",
    "}).__root__.create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e0aff64d-b70f-4e72-bd03-bf3edbe02b4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name='Iris' feature_columns=[ColumnConfig(name='sepal length (cm)', data_type=NumericDataType(domain_kind='numeric')), ColumnConfig(name='sepal width (cm)', data_type=NumericDataType(domain_kind='numeric')), ColumnConfig(name='petal length (cm)', data_type=NumericDataType(domain_kind='numeric')), ColumnConfig(name='petal width (cm)', data_type=NumericDataType(domain_kind='numeric'))] target_columns=[ColumnConfig(name='species', data_type=CategoricalDataType(domain_kind='categorical', classes={}))] featurizers=[] transforms=[StandardScalerConfig(type='sklearn.preprocessing.StandardScaler', constructor_args=StandardScalerConstructorArgs(with_mean=True, with_std=True), name='sepal length (cm)-transformer-0', forward_args={'X': '$sepal length (cm)'}), StandardScalerConfig(type='sklearn.preprocessing.StandardScaler', constructor_args=StandardScalerConstructorArgs(with_mean=True, with_std=True), name='sepal width (cm)-transformer-0', forward_args={'X': '$sepal width (cm)'}), StandardScalerConfig(type='sklearn.preprocessing.StandardScaler', constructor_args=StandardScalerConstructorArgs(with_mean=True, with_std=True), name='petal length (cm)-transformer-0', forward_args={'X': '$petal length (cm)'}), StandardScalerConfig(type='sklearn.preprocessing.StandardScaler', constructor_args=StandardScalerConstructorArgs(with_mean=True, with_std=True), name='petal width (cm)-transformer-0', forward_args={'X': '$petal width (cm)'}), LabelEncoderConfig(type='sklearn.preprocessing.LabelEncoder', constructor_args=None, name='species-transformer-0', forward_args={'X': '$species'})]\n",
      "name='SAMPL' feature_columns=[ColumnConfig(name='smiles', data_type=SmileDataType(domain_kind='smiles'))] target_columns=[ColumnConfig(name='expt', data_type=NumericDataType(domain_kind='numeric'))] featurizers=[FPVecFilteredTransformerConfig(type='molfeat.trans.fp.FPVecFilteredTransformer', constructor_args=FPVecFilteredTransformerConstructorArgs(del_invariant=None, length=None), name='smiles-feat-0', forward_args={'X': '$smiles'})] transforms=[StandardScalerConfig(type='sklearn.preprocessing.StandardScaler', constructor_args=StandardScalerConstructorArgs(with_mean=True, with_std=True), name='expt-transformer-0', forward_args={'X': '$expt'})]\n"
     ]
    }
   ],
   "source": [
    "class ColumnConfigWithPreprocessing(CamelCaseModel):\n",
    "    name: str\n",
    "    data_type: data_types.DataType\n",
    "    transforms: Union[None, List[CreateFromType]] = None\n",
    "    featurizers: Union[None, List[CreateFromType]] = None\n",
    "    \n",
    "    \n",
    "class DatasetConfig(CamelCaseModel):\n",
    "    name: str\n",
    "    feature_columns: List[ColumnConfig]\n",
    "    target_columns: List[ColumnConfig]\n",
    "    featurizers: List[Featurizer]\n",
    "    transforms: List[Transformer]\n",
    "    \n",
    "    \n",
    "class DatasetConfigWithPreprocessing(CamelCaseModel, YAML_Model):\n",
    "    name: str\n",
    "    target_columns: List[ColumnConfigWithPreprocessing]\n",
    "    feature_columns: List[ColumnConfigWithPreprocessing]\n",
    "    \n",
    "    def to_dataset_config(self) -> DatasetConfig:\n",
    "        featurizers = []\n",
    "        transforms = []\n",
    "        for col in self.feature_columns + self.target_columns:\n",
    "            if col.featurizers:\n",
    "                previous_key = col.name\n",
    "                for idx, col_featurizer in enumerate(col.featurizers):\n",
    "                    key = f'{col.name}-feat-{idx}'\n",
    "                    featurizer_args = col_featurizer.dict() | {\n",
    "                            'name': key,\n",
    "                            'forward_args': {\n",
    "                                'X': f'${previous_key}'\n",
    "                            }\n",
    "                        }\n",
    "                    if featurizer_args[\"constructor_args\"] is None:\n",
    "                        featurizer_args.pop(\"constructor_args\")\n",
    "                    featurizers.append(FeaturizerConfig.parse_obj(\n",
    "                        featurizer_args\n",
    "                    ))\n",
    "                    previous_key = key\n",
    "            if col.transforms:\n",
    "                previous_key = col.name\n",
    "                for idx, col_transform in enumerate(col.transforms):\n",
    "                    key = f'{col.name}-transformer-{idx}'\n",
    "                    transformer_args = col_transform.dict() | {\n",
    "                        'name': key,\n",
    "                        'forward_args': {\n",
    "                            'X': f'${previous_key}'\n",
    "                        }\n",
    "                    }\n",
    "                    if transformer_args[\"constructor_args\"] is None:\n",
    "                        transformer_args.pop(\"constructor_args\")\n",
    "                    transforms.append(TransformConfig.parse_obj(transformer_args))\n",
    "                    previous_key = key\n",
    "        return DatasetConfig(\n",
    "            name=self.name,\n",
    "            target_columns=[\n",
    "                ColumnConfig(name=col.name,data_type=col.data_type)\n",
    "                for col in self.target_columns\n",
    "            ],\n",
    "            feature_columns=[\n",
    "                ColumnConfig(name=col.name,data_type=col.data_type)\n",
    "                for col in self.feature_columns\n",
    "            ],\n",
    "            featurizers=[feat.__root__ for feat in featurizers],\n",
    "            transforms=[transf.__root__ for transf in transforms]\n",
    "        )\n",
    "            \n",
    "iris_config = DatasetConfigWithPreprocessing.from_yaml_str(\"\"\"\n",
    "name: Iris\n",
    "targetColumns:\n",
    "  - name: species\n",
    "    dataType:\n",
    "      domainKind: categorical\n",
    "      classes: {}\n",
    "    transforms:\n",
    "      - type: sklearn.preprocessing.LabelEncoder\n",
    "featureColumns:\n",
    "  - name: sepal length (cm)\n",
    "    dataType:\n",
    "      domainKind: numeric\n",
    "      unit: cm\n",
    "    transforms:\n",
    "      - type: sklearn.preprocessing.StandardScaler\n",
    "  - name: sepal width (cm)\n",
    "    dataType:\n",
    "      domainKind: numeric\n",
    "      unit: cm\n",
    "    transforms:\n",
    "      - type: sklearn.preprocessing.StandardScaler\n",
    "  - name: petal length (cm)\n",
    "    dataType:\n",
    "      domainKind: numeric\n",
    "      unit: cm\n",
    "    transforms:\n",
    "      - type: sklearn.preprocessing.StandardScaler\n",
    "  - name: petal width (cm)\n",
    "    dataType:\n",
    "      domainKind: numeric\n",
    "      unit: cm\n",
    "    transforms:\n",
    "      - type: sklearn.preprocessing.StandardScaler\n",
    "\"\"\").to_dataset_config()\n",
    "\n",
    "sampl_config = DatasetConfigWithPreprocessing.from_yaml_str(\"\"\"\n",
    "name: SAMPL\n",
    "featureColumns:\n",
    "  - name: smiles\n",
    "    dataType:\n",
    "      domainKind: smiles\n",
    "    featurizers:\n",
    "      - type: molfeat.trans.fp.FPVecFilteredTransformer\n",
    "targetColumns:\n",
    "  - name: expt\n",
    "    dataType:\n",
    "      domainKind: numeric\n",
    "    transforms:\n",
    "      - type: sklearn.preprocessing.StandardScaler\n",
    "\"\"\").to_dataset_config()\n",
    "\n",
    "print(iris_config)\n",
    "print(sampl_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d238b881-fe47-48c9-9f3a-37d0636a65b1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
       "0                  5.1               3.5                1.4               0.2\n",
       "1                  4.9               3.0                1.4               0.2\n",
       "2                  4.7               3.2                1.3               0.2\n",
       "3                  4.6               3.1                1.5               0.2\n",
       "4                  5.0               3.6                1.4               0.2\n",
       "..                 ...               ...                ...               ...\n",
       "145                6.7               3.0                5.2               2.3\n",
       "146                6.3               2.5                5.0               1.9\n",
       "147                6.5               3.0                5.2               2.0\n",
       "148                6.2               3.4                5.4               2.3\n",
       "149                5.9               3.0                5.1               1.8\n",
       "\n",
       "[150 rows x 4 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_cols = list(map(lambda x: x.name, iris_config.target_columns))\n",
    "feature_cols = list(map(lambda x: x.name, iris_config.feature_columns))\n",
    "print(feature_cols)\n",
    "iris_df.loc[:, feature_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "e6c01eeb-7999-4e0a-a5fe-f879c1c56bea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node: {'type': 'sklearn.preprocessing.StandardScaler', 'constructorArgs': {'with_mean': True, 'with_std': True}, 'name': 'sepal length (cm)-transformer-0', 'forwardArgs': {'X': '$sepal length (cm)'}}\n",
      "Node: {'type': 'sklearn.preprocessing.StandardScaler', 'constructorArgs': {'with_mean': True, 'with_std': True}, 'name': 'sepal width (cm)-transformer-0', 'forwardArgs': {'X': '$sepal width (cm)'}}\n",
      "Node: {'type': 'sklearn.preprocessing.StandardScaler', 'constructorArgs': {'with_mean': True, 'with_std': True}, 'name': 'petal length (cm)-transformer-0', 'forwardArgs': {'X': '$petal length (cm)'}}\n",
      "Node: {'type': 'sklearn.preprocessing.StandardScaler', 'constructorArgs': {'with_mean': True, 'with_std': True}, 'name': 'petal width (cm)-transformer-0', 'forwardArgs': {'X': '$petal width (cm)'}}\n",
      "Node: {'type': 'sklearn.preprocessing.LabelEncoder', 'constructorArgs': None, 'name': 'species-transformer-0', 'forwardArgs': {'X': '$species'}}\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Failed to fit \"LabelEncoderConfig(type='sklearn.preprocessing.LabelEncoder', constructor_args=None, name='species-transformer-0', forward_args={'X': '$species'})\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[93], line 132\u001b[0m, in \u001b[0;36mPreprocessingPipeline.fit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLabelEncoder\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config\u001b[38;5;241m.\u001b[39mtype:\n\u001b[0;32m--> 132\u001b[0m     \u001b[43mtransform\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mTypeError\u001b[0m: wrapped() missing 1 required positional argument: 'X'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[93], line 146\u001b[0m\n\u001b[1;32m    144\u001b[0m iris_preprocessing \u001b[38;5;241m=\u001b[39m PreprocessingPipeline(iris_config)\n\u001b[1;32m    145\u001b[0m X, y \u001b[38;5;241m=\u001b[39m iris_preprocessing\u001b[38;5;241m.\u001b[39mget_X_and_y(iris_df)\n\u001b[0;32m--> 146\u001b[0m \u001b[43miris_preprocessing\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[93], line 136\u001b[0m, in \u001b[0;36mPreprocessingPipeline.fit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    134\u001b[0m             transform\u001b[38;5;241m.\u001b[39mfit_transform(X\u001b[38;5;241m=\u001b[39mX, y\u001b[38;5;241m=\u001b[39my)\n\u001b[1;32m    135\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m--> 136\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFailed to fit \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m pformat(config))\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fitted \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Failed to fit \"LabelEncoderConfig(type='sklearn.preprocessing.LabelEncoder', constructor_args=None, name='species-transformer-0', forward_args={'X': '$species'})\""
     ]
    }
   ],
   "source": [
    "from pprint import pformat\n",
    "class PreprocessingPipeline:\n",
    "    \"\"\"\n",
    "    Preprocesses the dataset.\n",
    "\n",
    "    Args:\n",
    "        dataset_config: The object describing the columns and data_types of the dataset.\n",
    "        df: The :class:`pd.DataFrame` that holds the dataset data.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        dataset_config: DatasetConfig,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Creates the pipeline steps without executing them.\n",
    "\n",
    "        Args:\n",
    "            dataset_config: The object describing the pipeline.\n",
    "        \"\"\"\n",
    "        self.dataset_config = dataset_config\n",
    "        self.featurizers = []\n",
    "        self.transforms = []\n",
    "        self.featurizers_config = {\n",
    "            feat.name: feat for feat in dataset_config.featurizers\n",
    "        }\n",
    "        self.transforms_config = {\n",
    "            transform.name: transform for transform in dataset_config.transforms\n",
    "        }\n",
    "        self.featurizers = {\n",
    "            feat.name: feat.create() for feat in dataset_config.featurizers\n",
    "        }\n",
    "        self.transforms = {\n",
    "            transform.name: transform.create() for transform in dataset_config.transforms\n",
    "        }\n",
    "        self._fitted = False\n",
    "\n",
    "\n",
    "    def _prepare_transform(self, func: Any):\n",
    "        if isinstance(func, sklern.base.TransformerMixin):\n",
    "            return func\n",
    "        elif callable(func):\n",
    "            return sklearn.preprocessing.FunctionTransformer(func)\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                'func must be one of %r' % (\n",
    "                    ['sklearn.base.TransformerMixin', 'Callable']\n",
    "                )\n",
    "            )\n",
    "\n",
    "       \n",
    "                \n",
    "    def get_X_and_y(self, df: pd.DataFrame) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "        feature_columns = [\n",
    "            col.name\n",
    "            for col in self.dataset_config.feature_columns\n",
    "        \n",
    "        ]\n",
    "        target_columns = [\n",
    "            col.name\n",
    "            for col in self.dataset_config.target_columns\n",
    "        ]\n",
    "        return df.loc[:, feature_columns], df.loc[:, target_columns]\n",
    "\n",
    "    def fit(\n",
    "        self,\n",
    "        X: Union[pd.DataFrame, np.ndarray],\n",
    "        y: Union[pd.DataFrame, np.ndarray, None] = None\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Fits the featurizers and transforms to the data.\n",
    "        \"\"\"\n",
    "        \n",
    "        feats, transforms = map(list, dataset_topo_sort(self.dataset_config))\n",
    "        \n",
    "        if not isinstance(X, pd.DataFrame):\n",
    "            X = pd.DataFrame(X, columns=[col.name for col in self.dataset_config.feature_columns])\n",
    "\n",
    "        if not isinstance(y, pd.DataFrame):\n",
    "            y = pd.DataFrame(y, columns=[col.name for col in self.dataset_config.target_columns])\n",
    "            \n",
    "        for config in feats:\n",
    "            feat = self.featurizers[config.name]\n",
    "            try:\n",
    "                if 'LabelEncoder' in config.type: # special case for featurizers that take only y\n",
    "                    feat.fit(y=y)\n",
    "                else:\n",
    "                    feat.fit(X=X, y=y)\n",
    "            except:\n",
    "                raise RuntimeError('Failed to fit %r' % pformat(config))\n",
    "\n",
    "        for config in transforms:\n",
    "            transform = self.transforms[config.name]\n",
    "            try:\n",
    "                if 'LabelEncoder' in config.type:\n",
    "                    transform.fit(y=y)\n",
    "                else:\n",
    "                    transform.fit(X=X, y=y)\n",
    "            except:\n",
    "                raise RuntimeError('Failed to fit %r' % pformat(config))\n",
    "        self._fitted = True\n",
    "\n",
    "\n",
    "    def fit_transform(\n",
    "        self,\n",
    "        X: Union[pd.DataFrame, np.ndarray],\n",
    "        y: Union[pd.DataFrame, np.ndarray, None] = None\n",
    "    ):\n",
    "\n",
    "        feats, transforms = map(list, dataset_topo_sort(self.dataset_config))\n",
    "        \n",
    "        if not isinstance(X, pd.DataFrame):\n",
    "            X = pd.DataFrame(X, columns=[col.name for col in self.dataset_config.feature_columns])\n",
    "\n",
    "        if not isinstance(y, pd.DataFrame):\n",
    "            y = pd.DataFrame(y, columns=[col.name for col in self.dataset_config.target_columns])\n",
    "            \n",
    "        for config in feats:\n",
    "            feat = self.featurizers[config.name]\n",
    "            try:\n",
    "                if 'LabelEncoder' in config.type: # special case for featurizers that take only y\n",
    "                    feat.fit_transform(y=y)\n",
    "                else:\n",
    "                    feat.fit_transform(X=X, y=y)\n",
    "            except:\n",
    "                raise RuntimeError('Failed to fit %r' % pformat(config))\n",
    "\n",
    "        for config in transforms:\n",
    "            transform = self.transforms[config.name]\n",
    "            try:\n",
    "                if 'LabelEncoder' in config.type:\n",
    "                    transform.fit_transform(y=y)\n",
    "                else:\n",
    "                    transform.fit_transform(X=X, y=y)\n",
    "            except:\n",
    "                raise RuntimeError('Failed to fit %r' % pformat(config))\n",
    "        self._fitted = True\n",
    "\n",
    "\n",
    "    def transform(self, data: Union[pd.DataFrame, np.ndarray]):\n",
    "        ...\n",
    "\n",
    "\n",
    "iris_preprocessing = PreprocessingPipeline(iris_config)\n",
    "X, y = iris_preprocessing.get_X_and_y(iris_df)\n",
    "iris_preprocessing.fit_transform(X, y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
