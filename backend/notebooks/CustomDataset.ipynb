{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b13a686-0277-476a-b543-32fbab4c416d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/requests/__init__.py:109: RequestsDependencyWarning: urllib3 (1.26.9) or chardet (5.0.0)/charset_normalizer (2.0.12) doesn't match a supported version!\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.data import Data as PyGData, Dataset as PyGDataset\n",
    "from torch_geometric.loader import DataLoader\n",
    "from typing import Literal, List, Union\n",
    "import pandas as pd\n",
    "from abc import ABC, abstractmethod\n",
    "from app.features.model.schema.configs import ModelConfig\n",
    "import networkx as nx\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c028f8ea-6ea1-4603-8bec-66c80dd13d64",
   "metadata": {},
   "source": [
    "## Loading config for the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5aefa90c-2d1e-4d17-8628-1f4b1b04d133",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = \"\"\"name: GNNExample\n",
    "dataset:\n",
    "  name: Small Zinc dataset\n",
    "  target_column: tpsa\n",
    "  feature_columns:\n",
    "    - smiles\n",
    "    - mwt\n",
    "\n",
    "featurizers:\n",
    "  - name: MolToGraphFeaturizer\n",
    "    type: app.features.model.featurizers.MoleculeFeaturizer\n",
    "    input:\n",
    "      - smiles\n",
    "    args:\n",
    "      allow_unknown: false\n",
    "      sym_bond_list: true\n",
    "      per_atom_fragmentation: false\n",
    "\n",
    "layers:\n",
    "\n",
    "  # Start fst branch (from featurizer)\n",
    "  - name: GCN1\n",
    "    type: torch_geometric.nn.GCNConv\n",
    "    args:\n",
    "      in_channels: 26\n",
    "      out_channels: 64\n",
    "    input: MolToGraphFeaturizer\n",
    "\n",
    "  - name: GCN1_Activation\n",
    "    type: torch.nn.ReLU\n",
    "    input: GCN1\n",
    "\n",
    "  - name: GCN2 \n",
    "    type: torch_geometric.nn.GCNConv\n",
    "    input: GCN1_Activation\n",
    "    args:\n",
    "      in_channels: 64\n",
    "      out_channels: 64\n",
    "\n",
    "  - name: GCN2_Activation\n",
    "    type: torch.nn.ReLU\n",
    "    input: GCN2\n",
    "\n",
    "  - name: GCN3\n",
    "    type: torch_geometric.nn.GCNConv\n",
    "    input: GCN2_Activation\n",
    "    args:\n",
    "      in_channels: 64\n",
    "      out_channels: 64\n",
    "\n",
    "  - name: GCN3_Activation\n",
    "    type: torch.nn.ReLU\n",
    "    input: GCN3\n",
    "\n",
    "  - name: AddPool\n",
    "    type: app.features.model.layers.GlobalPooling\n",
    "    input: GCN3_Activation\n",
    "    args:\n",
    "      aggr: 'sum'\n",
    "  # End of fst branch\n",
    "\n",
    "  # Second branch would simply be linear layers in mwt\n",
    "  - name: Linear1\n",
    "    type: torch.nn.Linear\n",
    "    args:\n",
    "      in_features: 1\n",
    "      out_features: 10\n",
    "    input: mwt\n",
    "\n",
    "  - name: Combiner\n",
    "    type: app.features.model.layers.Concat\n",
    "    input: ['AddPool', 'Linear1']\n",
    "\n",
    "  - name: LinearJoined\n",
    "    type: torch.nn.Linear\n",
    "    input: Combiner\n",
    "    args:\n",
    "      in_features: 74\n",
    "      out_features: 1\n",
    "\n",
    "  - name: OutputSigmoid\n",
    "    type: torch.nn.Sigmoid\n",
    "    input: LinearJoined\n",
    "\"\"\"\n",
    "\n",
    "model = ModelConfig.from_yaml(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5537836d-db74-4bf7-9741-22ec9dfc7ec7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[AppmoleculefeaturizerLayerConfig(name='MolToGraphFeaturizer', input=['smiles'], type='app.features.model.featurizers.MoleculeFeaturizer', args=AppmoleculefeaturizerArgs(allow_unknown=False, sym_bond_list=True, per_atom_fragmentation=False))]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.featurizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6bbd0ae5-296f-41fb-9755-05ab9204f3d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetConfig(name='Small Zinc dataset', target_column='tpsa', feature_columns=['smiles', 'mwt'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1aa6d30-98bf-4cda-83aa-3cc6abb7288d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Exploring the dataset manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9e2a92e6-341d-49b7-ae0a-a3fd9f6dae44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>zinc_id</th>\n",
       "      <th>smiles</th>\n",
       "      <th>mwt</th>\n",
       "      <th>logp</th>\n",
       "      <th>heavy_atoms</th>\n",
       "      <th>n_rings</th>\n",
       "      <th>heteroatoms</th>\n",
       "      <th>tpsa</th>\n",
       "      <th>hacceptors</th>\n",
       "      <th>hdonors</th>\n",
       "      <th>rotatable_bonds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ZINC000000000007</td>\n",
       "      <td>C=CCc1ccc(OCC(=O)N(CC)CC)c(OC)c1</td>\n",
       "      <td>277.364</td>\n",
       "      <td>2.6709</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>38.77</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ZINC000000000010</td>\n",
       "      <td>C[C@@]1(c2ccccc2)OC(C(=O)O)=CC1=O</td>\n",
       "      <td>218.208</td>\n",
       "      <td>1.4696</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>63.60</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ZINC000000000011</td>\n",
       "      <td>COc1cc(Cc2cnc(N)nc2N)cc(OC)c1N(C)C</td>\n",
       "      <td>303.366</td>\n",
       "      <td>1.3150</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>99.52</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ZINC000000000012</td>\n",
       "      <td>O=C(C[S@@](=O)C(c1ccccc1)c1ccccc1)NO</td>\n",
       "      <td>289.356</td>\n",
       "      <td>2.0301</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>66.40</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ZINC000000000014</td>\n",
       "      <td>CC[C@H]1[C@H](O)N2[C@H]3C[C@@]45c6ccccc6N(C)[C...</td>\n",
       "      <td>326.440</td>\n",
       "      <td>1.5545</td>\n",
       "      <td>24</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>46.94</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            zinc_id                                             smiles  \\\n",
       "0  ZINC000000000007                   C=CCc1ccc(OCC(=O)N(CC)CC)c(OC)c1   \n",
       "1  ZINC000000000010                  C[C@@]1(c2ccccc2)OC(C(=O)O)=CC1=O   \n",
       "2  ZINC000000000011                 COc1cc(Cc2cnc(N)nc2N)cc(OC)c1N(C)C   \n",
       "3  ZINC000000000012               O=C(C[S@@](=O)C(c1ccccc1)c1ccccc1)NO   \n",
       "4  ZINC000000000014  CC[C@H]1[C@H](O)N2[C@H]3C[C@@]45c6ccccc6N(C)[C...   \n",
       "\n",
       "       mwt    logp  heavy_atoms  n_rings  heteroatoms   tpsa  hacceptors  \\\n",
       "0  277.364  2.6709           20        1            4  38.77           3   \n",
       "1  218.208  1.4696           16        2            4  63.60           3   \n",
       "2  303.366  1.3150           22        2            7  99.52           7   \n",
       "3  289.356  2.0301           20        2            5  66.40           3   \n",
       "4  326.440  1.5545           24       12            4  46.94           4   \n",
       "\n",
       "   hdonors  rotatable_bonds  \n",
       "0        0                8  \n",
       "1        1                2  \n",
       "2        2                5  \n",
       "3        2                5  \n",
       "4        2                1  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zinc_example = pd.read_csv(\"./zinc.csv\")\n",
    "zinc_example.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "028f4345-9f6b-48e2-87f6-7d6d7cc9c0e6",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Building the CustomDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5bfdb86f-e10b-4200-904c-dcf52d124259",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections.abc import MutableMapping, Mapping, Sequence\n",
    "from typing import Any, Callable, Dict, Iterable, List, Optional\n",
    "import weakref\n",
    "import torch\n",
    "from torch_sparse import SparseTensor\n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "\n",
    "def recursive_apply_(data: Any, function: Callable) -> None:\n",
    "    if isinstance(data, torch.Tensor):\n",
    "        function(data)\n",
    "        return\n",
    "\n",
    "    if isinstance(data, tuple) and hasattr(data, \"_fields\"):  # Named Tuple\n",
    "        for value in data:\n",
    "            recursive_apply_(data, function)\n",
    "        return\n",
    "\n",
    "    if isinstance(data, Sequence) and not isinstance(data, str):\n",
    "        for value in data:\n",
    "            recursive_apply_(value, function)\n",
    "        return\n",
    "\n",
    "    if isinstance(data, Mapping):\n",
    "        for value in data.values:\n",
    "            recursive_apply_(value, function)\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        function(data)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "\n",
    "def recursive_apply(data: Any, function: Callable) -> Any:\n",
    "    if isinstance(data, torch.Tensor):\n",
    "        return function(data)\n",
    "\n",
    "    if isinstance(data, torch.nn.utils.rnn.PackedSequence):\n",
    "        return function(data)\n",
    "\n",
    "    if isinstance(data, tuple) and hasattr(data, \"_fields\"):\n",
    "        return type(data)(*(recursive_apply(d, function) for d in data))\n",
    "\n",
    "    if isinstance(data, Sequence) and not isinstance(data, str):\n",
    "        return [recursive_apply(data, function) for d in data]\n",
    "\n",
    "    if isinstance(data, Mapping):\n",
    "        return {key: recursive_apply(data[key], function) for key in data}\n",
    "\n",
    "    try:\n",
    "        return function(data)\n",
    "    except:\n",
    "        return data\n",
    "\n",
    "\n",
    "def size_repr(key: Any, value: Any, indent: int = 0) -> str:\n",
    "    pad = \" \" * indent\n",
    "\n",
    "    if isinstance(value, torch.Tensor) and value.dim() == 0:\n",
    "        out = value.item()\n",
    "    elif isinstance(value, torch.Tensor):\n",
    "        out = str(list(value.size()))\n",
    "    elif isinstance(value, np.ndarray):\n",
    "        out = str(list(value.shape))\n",
    "    elif isinstance(value, SparseTensor):\n",
    "        out = str(value.sizes())[:-1] + f\", nnz={value.nnz()}]\"\n",
    "    elif isinstance(value, str):\n",
    "        out = f\"'{value}'\"\n",
    "    elif isinstance(value, Sequence):\n",
    "        out = str([len(value)])\n",
    "    elif isinstance(value, Mapping) and len(value) == 0:\n",
    "        out = \"{}\"\n",
    "    elif (\n",
    "        isinstance(value, Mapping)\n",
    "        and len(value) == 1\n",
    "        and not isinstance(list(value.values())[0], Mapping)\n",
    "    ):\n",
    "        lines = [size_repr(k, v, 0) for k, v in value.items()]\n",
    "        out = \"{ \" + \", \".join(lines) + \" }\"\n",
    "    elif isinstance(value, Mapping):\n",
    "        lines = [size_repr(k, v, indent + 2) for k, v in value.items()]\n",
    "        out = \"{\\n\" + \",\\n\".join(lines) + \"\\n\" + pad + \"}\"\n",
    "    else:\n",
    "        out = str(value)\n",
    "\n",
    "    key = str(key).replace(\"'\", \"\")\n",
    "    if isinstance(value, BaseStorage):\n",
    "        return f\"{pad}\\033[1m{key}\\033[0m={out}\"\n",
    "    else:\n",
    "        return f\"{pad}{key}={out}\"\n",
    "\n",
    "\n",
    "class MappingView(object):\n",
    "    def __init__(self, mapping: Mapping, *args: List[str]) -> None:\n",
    "        self._mapping = mapping\n",
    "        self._args = args\n",
    "\n",
    "    def _keys(self) -> Iterable:\n",
    "        if len(self._args) == 0:\n",
    "            return self._mapping.keys()\n",
    "        return [arg for arg in self._args if arg in self._mapping]\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self._keys())\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        mapping = {key: self._mapping[key] for key in self._keys()}\n",
    "        return f\"{self.__class__.__name__}({mapping})\"\n",
    "\n",
    "    __class_getitem__ = classmethod(type([]))\n",
    "\n",
    "\n",
    "class KeysView(MappingView):\n",
    "    def __iter__(self) -> Iterable:\n",
    "        yield from self._keys()\n",
    "\n",
    "\n",
    "class ValuesView(MappingView):\n",
    "    def __iter__(self) -> Iterable:\n",
    "        for key in self._keys():\n",
    "            yield self._mapping[key]\n",
    "\n",
    "\n",
    "class ItemsView(MappingView):\n",
    "    def __iter__(self) -> Iterable:\n",
    "        for key in self._keys():\n",
    "            yield (key, self._mapping[key])\n",
    "\n",
    "\n",
    "class BaseStorage(MutableMapping):\n",
    "    def __init__(\n",
    "        self, _mapping: Optional[Dict[str, Any]] = None, **kwargs\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self._mapping = {}\n",
    "\n",
    "        # Setup all attributes that comes from _mapping\n",
    "        for key, value in (_mapping or {}).items():\n",
    "            setattr(self, key, value)\n",
    "\n",
    "        # Transform all arguments passed by kwargs\n",
    "        # in new atttributes for the base storage instance\n",
    "        for key, value in kwargs.items():\n",
    "            setattr(self, key, value)\n",
    "\n",
    "    @property\n",
    "    def _key(self) -> Any:\n",
    "        return None\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self._mapping)\n",
    "\n",
    "    def __getattr__(self, key: str) -> Any:\n",
    "        if key == \"_mapping\":\n",
    "            self._mapping = {}\n",
    "            return self._mapping\n",
    "\n",
    "        try:\n",
    "            return self[key]\n",
    "        except KeyError:\n",
    "            raise AttributeError(\n",
    "                f\"'{self.__class__.__name__}' object has no attribute '{key}'\"\n",
    "            )\n",
    "\n",
    "    def __setattr__(self, key: str, value: Any) -> None:\n",
    "        if key == \"_parent\":\n",
    "            self.__dict__[key] = weakref.ref(value)\n",
    "        elif key[:1] == \"_\":\n",
    "            self.__dict__[key] = value\n",
    "        else:\n",
    "            self[key] = value\n",
    "\n",
    "    def __delattr__(self, key: str) -> None:\n",
    "        if key[:1] == \"_\":\n",
    "            del self.__dict__[key]\n",
    "        else:\n",
    "            del self[key]\n",
    "\n",
    "    def __getitem__(self, key: str) -> Any:\n",
    "        return self._mapping[key]\n",
    "\n",
    "    def __setitem__(self, key: str, value: Any) -> None:\n",
    "        if value is None and key in self._mapping:\n",
    "            del self._mapping[key]\n",
    "        elif value is not None:\n",
    "            self._mapping[key] = value\n",
    "\n",
    "    def __delitem__(self, key: str) -> None:\n",
    "        if key in self._mapping:\n",
    "            del self._mapping[key]\n",
    "\n",
    "    def __iter__(self) -> Iterable:\n",
    "        return iter(self._mapping)\n",
    "\n",
    "    def __copy__(self):\n",
    "        out = self.__class__.__new__(self.__class__)\n",
    "\n",
    "        for key, value in self.__dict__.items():\n",
    "            out.__dict__[key] = value\n",
    "\n",
    "        out._mapping = copy.copy(out._mapping)\n",
    "        return out\n",
    "\n",
    "    def __deepcopy__(self, memo):\n",
    "        out = self.__class__.__new__(self.__class__)\n",
    "\n",
    "        for key, value in self.__dict__.items():\n",
    "            out.__dict__[key] = value\n",
    "\n",
    "        out._mapping = copy.deepcopy(out._mapping, memo)\n",
    "        return out\n",
    "\n",
    "    def __getstate__(self) -> Dict[str, Any]:\n",
    "        out = self.__dict__.copy()\n",
    "\n",
    "        _parent = out.get(\"_parent\", None)\n",
    "        if _parent is not None:\n",
    "            out[\"_parent\"] = _parent()\n",
    "\n",
    "        return out\n",
    "\n",
    "    def __setstate__(self, mapping: Dict[str, Any]) -> None:\n",
    "        for key, value in mapping.items():\n",
    "            self.__dict__[key] = value\n",
    "\n",
    "        _parent = self.__dict__.get(\"_parent\", None)\n",
    "        if _parent is not None:\n",
    "            self.__dict__[\"_parent\"] = weakref.ref(_parent)\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return repr(self._mapping)\n",
    "\n",
    "    def keys(self, *args: List[str]) -> KeysView:\n",
    "        return KeysView(self._mapping, *args)\n",
    "\n",
    "    def values(self, *args: List[str]) -> ValuesView:\n",
    "        return ValuesView(self._mapping, *args)\n",
    "\n",
    "    def items(self, *args: List[str]) -> ItemsView:\n",
    "        return ItemsView(self._mapping, *args)\n",
    "\n",
    "    def apply_(self, function: Callable, *args: List[str]):\n",
    "        for key, value in self.items(*args):\n",
    "            self[key] = recursive_apply(value, function)\n",
    "        return self\n",
    "\n",
    "    def apply(self, function: Callable, *args: List[str]):\n",
    "        for key, value in self.items(*args):\n",
    "            self[key] = recursive_apply(value, function)\n",
    "        return self\n",
    "\n",
    "\n",
    "## instance = DataInstance\n",
    "## instance.batch\n",
    "## instance.MolFeaturizer\n",
    "## instance.target\n",
    "## instance.any = ...\n",
    "class DataInstance(BaseStorage):\n",
    "    def __init__(self, y=None, **kwargs):\n",
    "        self.__dict__[\"_store\"] = BaseStorage(_parent=self)\n",
    "\n",
    "        if y is not None:\n",
    "            self.y = y\n",
    "\n",
    "        for key, value in kwargs.items():\n",
    "            setattr(self, key, value)\n",
    "\n",
    "    def __getitem__(self, key: str) -> Any:\n",
    "        return self._store[key]\n",
    "\n",
    "    def __setitem__(self, key: str, value: Any) -> None:\n",
    "        self._store[key] = value\n",
    "\n",
    "    def __delitem__(self, key: str) -> None:\n",
    "        if key in self._store:\n",
    "            del self._store[key]\n",
    "\n",
    "    def __getattr__(self, key: str) -> Any:\n",
    "        if \"_store\" not in self.__dict__:\n",
    "            raise RuntimeError\n",
    "        return getattr(self._store, key)\n",
    "\n",
    "    def __setattr__(self, key: str, value: Any) -> None:\n",
    "        setattr(self._store, key, value)\n",
    "\n",
    "    def __delattr__(self, key: str, value: Any) -> None:\n",
    "        delattr(self._store, key)\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        cls = self.__class__.__name__\n",
    "        info = [size_repr(k, v, indent=2) for k, v in self._store.items()]\n",
    "        info = \",\\n\".join(info)\n",
    "        return f\"{cls}(\\n{info}\\n)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6d955b30-6e38-4325-983e-284bced9d0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset as TorchDataset\n",
    "\n",
    "\n",
    "class CustomDataset(TorchDataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        data: pd.DataFrame,\n",
    "        feature_columns,\n",
    "        featurizers_config,\n",
    "        target: str,\n",
    "    ) -> None:\n",
    "        self.data = data\n",
    "        self.target = target\n",
    "        self.columns = feature_columns\n",
    "        self._featurizers_config = featurizers_config\n",
    "\n",
    "        self.setup()\n",
    "\n",
    "    def _determine_task_type(self) -> str:\n",
    "        target_type = self.data.dtypes[self.target]\n",
    "\n",
    "        if \"float\" in target_type.name:\n",
    "            # If it is a float target, we treat the task as a regression\n",
    "            return \"regression\"\n",
    "\n",
    "        return AttributeError(\"Unsupported target type for prediction.\")\n",
    "\n",
    "    def setup(self):\n",
    "        # First we need to determine the type of the task\n",
    "        self._task_type = self._determine_task_type()\n",
    "        # After that we can instanciate all of the featurizers used to transform\n",
    "        # the columns\n",
    "        self._featurizers = {}\n",
    "        for featurizer_config in self._featurizers_config:\n",
    "            self._featurizers[\n",
    "                featurizer_config.name\n",
    "            ] = featurizer_config.create()\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index) -> DataInstance:\n",
    "        d = DataInstance()\n",
    "        sample = dict(self.data.iloc[index, :])\n",
    "\n",
    "        columns_to_include = self.columns.copy()\n",
    "        # We need to featurize all of the columns that pass into a\n",
    "        # featurizer before include in the data instance\n",
    "        for featurizer in self._featurizers_config:\n",
    "            d[featurizer.name] = self._featurizers[featurizer.name](\n",
    "                sample[featurizer.input[0]]\n",
    "            )\n",
    "            columns_to_include.remove(featurizer.input[0])\n",
    "\n",
    "        # After that we can include all of the columns that remains from the featurizers\n",
    "        for column in columns_to_include:\n",
    "            d[column] = sample[column]\n",
    "\n",
    "        return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "96864e13-3302-46df-89eb-40774b382e87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[AppmoleculefeaturizerLayerConfig(name='MolToGraphFeaturizer', input=['smiles'], type='app.features.model.featurizers.MoleculeFeaturizer', args=AppmoleculefeaturizerArgs(allow_unknown=False, sym_bond_list=True, per_atom_fragmentation=False))]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.featurizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "08384ebb-2185-45fa-ac75-2990ce091063",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetConfig(name='Small Zinc dataset', target_column='tpsa', feature_columns=['smiles', 'mwt'])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "93055fb0-3d32-485b-8f6e-e0110d87d7ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.CustomDataset at 0x7f1f4beae1c0>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = CustomDataset(\n",
    "    zinc_example,\n",
    "    model.dataset.feature_columns,\n",
    "    model.featurizers,\n",
    "    model.dataset.target_column,\n",
    ")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7b6c7534-541f-45b4-af1d-de3858904b8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataInstance(\n",
       "  MolToGraphFeaturizer=Data(x=[20, 26], edge_index=[2, 40], edge_attr=[40, 9]),\n",
       "  mwt=277.3639999999999\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "63c12de0-583e-42d2-8192-ff33861364fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MolToGraphFeaturizer': DataBatch(x=[78, 26], edge_index=[2, 162], edge_attr=[162, 9], batch=[78], ptr=[5]),\n",
       " 'mwt': tensor([277.3640, 218.2080, 303.3660, 289.3560])}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "b = next(iter(DataLoader(dataset, batch_size=4)))\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6895f521-f66d-4e92-9c56-cd90f6943f62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "        3, 3, 3, 3, 3, 3])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[\"MolToGraphFeaturizer\"].batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2dc673-4485-4d64-92f1-8b4500b4eb81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from app.features.dataset.model import Dataset\n",
    "\n",
    "\n",
    "class DataModule:\n",
    "    ## Data Module that will work similar to a lightning module\n",
    "    ## but with support to our data types\n",
    "\n",
    "    def __init__(self, dataset: Dataset, dataset_config, featurizers_config):\n",
    "        self.dataset_config = dataset_config\n",
    "        self.featurizers_config = featurizers_config\n",
    "\n",
    "        self.dataset_metadata = dataset\n",
    "        self.dataset_file = self.dataset_metadata.get_dataframe()\n",
    "\n",
    "        self.dataset_metadata.split_type\n",
    "        self.dataset_metadata.split_\n",
    "\n",
    "    def setup(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        pass\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        pass\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        pass\n",
    "\n",
    "    def _split_data(self):\n",
    "        pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
