{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a2f02d7-995c-4d19-849a-f1bcec562b4b",
   "metadata": {},
   "source": [
    "## Parse model config yaml file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e84236c-a798-438e-9b0e-d5857af10d5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/requests/__init__.py:109: RequestsDependencyWarning: urllib3 (1.26.9) or chardet (5.0.0)/charset_normalizer (2.0.12) doesn't match a supported version!\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import yaml\n",
    "\n",
    "from app.features.model.schema.configs import ModelConfig\n",
    "\n",
    "config = \"\"\"name: GNNExample\n",
    "\n",
    "dataset:\n",
    "  name: test_dataset_2\n",
    "  target_column: tpsa\n",
    "  feature_columns:\n",
    "    - smiles\n",
    "    - mwt\n",
    "\n",
    "featurizers:\n",
    "  - name: MolToGraphFeaturizer\n",
    "    type: app.features.model.featurizers.MoleculeFeaturizer\n",
    "    input:\n",
    "      - smiles\n",
    "    args:\n",
    "      allow_unknown: false\n",
    "      sym_bond_list: true\n",
    "      per_atom_fragmentation: false\n",
    "\n",
    "layers:\n",
    "\n",
    "  # Start fst branch (from featurizer)\n",
    "  - name: GCN1\n",
    "    type: torch_geometric.nn.GCNConv\n",
    "    args:\n",
    "      in_channels: 30\n",
    "      out_channels: 64\n",
    "    input: MolToGraphFeaturizer\n",
    "\n",
    "  - name: GCN1_Activation\n",
    "    type: torch.nn.ReLU\n",
    "    input: GCN1\n",
    "\n",
    "  - name: GCN2 \n",
    "    type: torch_geometric.nn.GCNConv\n",
    "    input: GCN1_Activation\n",
    "    args:\n",
    "      in_channels: 64\n",
    "      out_channels: 64\n",
    "\n",
    "  - name: GCN2_Activation\n",
    "    type: torch.nn.ReLU\n",
    "    input: GCN2\n",
    "\n",
    "  - name: GCN3\n",
    "    type: torch_geometric.nn.GCNConv\n",
    "    input: GCN2_Activation\n",
    "    args:\n",
    "      in_channels: 64\n",
    "      out_channels: 64\n",
    "\n",
    "  - name: GCN3_Activation\n",
    "    type: torch.nn.ReLU\n",
    "    input: GCN3\n",
    "\n",
    "  - name: AddPool\n",
    "    type: app.features.model.layers.GlobalPooling\n",
    "    input: GCN3_Activation\n",
    "    args:\n",
    "      aggr: 'sum'\n",
    "  # End of fst branch\n",
    "\n",
    "  # Second branch would simply be linear layers in mwt\n",
    "  - name: Linear1\n",
    "    type: torch.nn.Linear\n",
    "    args:\n",
    "      in_features: 1\n",
    "      out_features: 10\n",
    "    input: mwt\n",
    "\n",
    "  - name: Combiner\n",
    "    type: app.features.model.layers.Concat\n",
    "    input: ['AddPool', 'Linear1']\n",
    "\n",
    "  - name: LinearJoined\n",
    "    type: torch.nn.Linear\n",
    "    input: Combiner\n",
    "    args:\n",
    "      in_features: 74\n",
    "      out_features: 1\n",
    "\n",
    "  - name: OutputSigmoid\n",
    "    type: torch.nn.Sigmoid\n",
    "    input: LinearJoined\n",
    "\"\"\"\n",
    "\n",
    "model = ModelConfig.from_yaml(config)\n",
    "\n",
    "nx.draw(model.make_graph(), with_labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "61216733-ed52-48f4-9790-6528445bc99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch_geometric.nn as geom_nn\n",
    "from torch.nn import ReLU, Sigmoid\n",
    "from app.features.model.layers import GlobalPooling\n",
    "from app.features.model.layers import Concat\n",
    "\n",
    "edge_index_classes = ( geom_nn.MessagePassing )\n",
    "pooling_classes = ( GlobalPooling )\n",
    "activations = (ReLU, Sigmoid)\n",
    "\n",
    "def is_message_passing(layer):\n",
    "    \"\"\" x = layer(x, edge_index) \"\"\"\n",
    "    return isinstance(layer, geom_nn.MessagePassing)\n",
    "\n",
    "def is_graph_pooling(layer):\n",
    "    \"\"\" x = layer(x, batch) \"\"\"\n",
    "    return isinstance(layer, pooling_classes)\n",
    "\n",
    "def is_concat_layer(layer):\n",
    "    return isinstance(layer, Concat)\n",
    "\n",
    "def is_graph_activation(layer, layers_dict, previous):\n",
    "    \"\"\"\n",
    "    takes the a dictionary with nn.Modules and the keys of\n",
    "    previous layers, checking if \n",
    "    \"\"\"\n",
    "    if not isinstance(layer, activations):\n",
    "        return False\n",
    "    for name in previous:\n",
    "        if is_message_passing(layers_dict[name]) or is_graph_pooling(layers_dict[name]):\n",
    "            return True\n",
    "    return False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae8b99c1-334d-4128-8967-ea8f82e6ac31",
   "metadata": {},
   "source": [
    "### Input Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "611f5b48-5e15-4d5b-961f-ce603e6b07cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MolToGraphFeaturizer': Data(x=[3, 30], edge_index=[2, 4]),\n",
       " 'mwt': tensor([[230.]])}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch_geometric.data import Data\n",
    "import torch\n",
    "\n",
    "x = torch.ones(3, 30, dtype=torch.float)\n",
    "edge_index = torch.tensor([[0, 1, 1, 2], [1, 0, 2, 1]], dtype=torch.long)\n",
    "mwt = torch.tensor([[230.]], dtype=torch.float)\n",
    "\n",
    "dataset_input = {\n",
    "    'MolToGraphFeaturizer': Data(x=x, edge_index=edge_index, batch=None),\n",
    "    'mwt': mwt\n",
    "}\n",
    "dataset_input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6b071b-7f86-48e8-8929-3956e70a68de",
   "metadata": {},
   "source": [
    "### Custom Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "89f6cd44-c0e5-4bd8-83d7-008525504317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer:       GCNConv(30, 64)\n",
      "LayerConfig: name='GCN1' input='MolToGraphFeaturizer' type='torch_geometric.nn.GCNConv' args=TorchgeometricgcnconvArgs(in_channels=30, out_channels=64)\n",
      "Previous:    ['MolToGraphFeaturizer']\n",
      "Next:        ['GCN1_Activation']\n",
      "Inputs:      ['MolToGraphFeaturizer']\n",
      "Input:\n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])\n",
      "tensor([[0, 1, 1, 2],\n",
      "        [1, 0, 2, 1]])\n",
      "Output:\n",
      "Data(x=[3, 64], edge_index=[2, 4])\n",
      "Layer:       Linear(in_features=1, out_features=10, bias=True)\n",
      "LayerConfig: name='Linear1' input='mwt' type='torch.nn.Linear' args=TorchlinearArgs(in_features=1, out_features=10)\n",
      "Previous:    ['mwt']\n",
      "Next:        ['Combiner']\n",
      "Inputs:      ['mwt']\n",
      "Inputs:\n",
      "[tensor([[230.]])]\n",
      "torch.Size([1, 1])\n",
      "Output\n",
      "tensor([[ 215.6506,  -49.1663,   18.2633,   -5.0933,  212.1023,  128.7159,\n",
      "         -138.5590,  -86.7516,  -88.1716,   37.0214]], grad_fn=<AddmmBackward>)\n",
      "Layer:       ReLU()\n",
      "LayerConfig: name='GCN1_Activation' input='GCN1' type='torch.nn.ReLU'\n",
      "Previous:    ['GCN1']\n",
      "Next:        ['GCN2']\n",
      "Inputs:      ['GCN1']\n",
      "[tensor([[230.]])]\n",
      "Output\n",
      "Data(x=[3, 64], edge_index=[2, 4])\n",
      "Layer:       GCNConv(64, 64)\n",
      "LayerConfig: name='GCN2' input='GCN1_Activation' type='torch_geometric.nn.GCNConv' args=TorchgeometricgcnconvArgs(in_channels=64, out_channels=64)\n",
      "Previous:    ['GCN1_Activation']\n",
      "Next:        ['GCN2_Activation']\n",
      "Inputs:      ['GCN1_Activation']\n",
      "Input:\n",
      "tensor([[0.4470, 0.3801, 2.2020, 0.0000, 0.0000, 0.0053, 0.0000, 0.0000, 0.2670,\n",
      "         0.0000, 0.8618, 1.0297, 0.0000, 0.0000, 0.0000, 0.4301, 0.0000, 0.0000,\n",
      "         0.1380, 0.1316, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1916,\n",
      "         0.0000, 0.5539, 0.1898, 0.1804, 0.5632, 0.3742, 0.3586, 0.0703, 1.3249,\n",
      "         0.4305, 0.5417, 0.1685, 0.0000, 0.0000, 0.0000, 0.4493, 0.8033, 0.1366,\n",
      "         0.1686, 0.9322, 0.0000, 0.1890, 0.3925, 0.4015, 0.1402, 0.0000, 0.2883,\n",
      "         0.5148, 0.0000, 0.0000, 0.1225, 0.0000, 0.9033, 0.2922, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.5659, 0.4812, 2.7877, 0.0000, 0.0000, 0.0067, 0.0000, 0.0000, 0.3381,\n",
      "         0.0000, 1.0910, 1.3035, 0.0000, 0.0000, 0.0000, 0.5445, 0.0000, 0.0000,\n",
      "         0.1747, 0.1666, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2425,\n",
      "         0.0000, 0.7012, 0.2403, 0.2283, 0.7130, 0.4737, 0.4540, 0.0890, 1.6774,\n",
      "         0.5450, 0.6857, 0.2134, 0.0000, 0.0000, 0.0000, 0.5688, 1.0170, 0.1730,\n",
      "         0.2134, 1.1802, 0.0000, 0.2392, 0.4969, 0.5083, 0.1774, 0.0000, 0.3649,\n",
      "         0.6517, 0.0000, 0.0000, 0.1551, 0.0000, 1.1435, 0.3700, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.4470, 0.3801, 2.2020, 0.0000, 0.0000, 0.0053, 0.0000, 0.0000, 0.2670,\n",
      "         0.0000, 0.8618, 1.0297, 0.0000, 0.0000, 0.0000, 0.4301, 0.0000, 0.0000,\n",
      "         0.1380, 0.1316, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1916,\n",
      "         0.0000, 0.5539, 0.1898, 0.1804, 0.5632, 0.3742, 0.3586, 0.0703, 1.3249,\n",
      "         0.4305, 0.5417, 0.1685, 0.0000, 0.0000, 0.0000, 0.4493, 0.8033, 0.1366,\n",
      "         0.1686, 0.9322, 0.0000, 0.1890, 0.3925, 0.4015, 0.1402, 0.0000, 0.2883,\n",
      "         0.5148, 0.0000, 0.0000, 0.1225, 0.0000, 0.9033, 0.2922, 0.0000, 0.0000,\n",
      "         0.0000]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0, 1, 1, 2],\n",
      "        [1, 0, 2, 1]])\n",
      "Output:\n",
      "Data(x=[3, 64], edge_index=[2, 4])\n",
      "Layer:       ReLU()\n",
      "LayerConfig: name='GCN2_Activation' input='GCN2' type='torch.nn.ReLU'\n",
      "Previous:    ['GCN2']\n",
      "Next:        ['GCN3']\n",
      "Inputs:      ['GCN2']\n",
      "[tensor([[230.]])]\n",
      "Output\n",
      "Data(x=[3, 64], edge_index=[2, 4])\n",
      "Layer:       GCNConv(64, 64)\n",
      "LayerConfig: name='GCN3' input='GCN2_Activation' type='torch_geometric.nn.GCNConv' args=TorchgeometricgcnconvArgs(in_channels=64, out_channels=64)\n",
      "Previous:    ['GCN2_Activation']\n",
      "Next:        ['GCN3_Activation']\n",
      "Inputs:      ['GCN2_Activation']\n",
      "Input:\n",
      "tensor([[0.5709, 0.0000, 0.0149, 0.3441, 0.0000, 0.0000, 0.0000, 0.0000, 0.0321,\n",
      "         0.0000, 0.7811, 0.3366, 0.0000, 0.0870, 0.0000, 0.0000, 0.0000, 0.1371,\n",
      "         0.0000, 0.5242, 0.2671, 0.0000, 0.0000, 0.0000, 0.4404, 0.4654, 0.8866,\n",
      "         0.0000, 0.0113, 0.0000, 0.2045, 0.0099, 0.2553, 0.7782, 0.0644, 0.0000,\n",
      "         0.0000, 0.4059, 0.0000, 0.8253, 0.0000, 0.5944, 0.0000, 0.2143, 0.0000,\n",
      "         0.4368, 0.6345, 0.0612, 0.0000, 0.0000, 0.0000, 0.0263, 0.0083, 0.4681,\n",
      "         0.0000, 0.8854, 0.2849, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.3228],\n",
      "        [0.6953, 0.0000, 0.0182, 0.4191, 0.0000, 0.0000, 0.0000, 0.0000, 0.0392,\n",
      "         0.0000, 0.9513, 0.4100, 0.0000, 0.1059, 0.0000, 0.0000, 0.0000, 0.1670,\n",
      "         0.0000, 0.6385, 0.3253, 0.0000, 0.0000, 0.0000, 0.5364, 0.5668, 1.0799,\n",
      "         0.0000, 0.0137, 0.0000, 0.2490, 0.0120, 0.3109, 0.9479, 0.0784, 0.0000,\n",
      "         0.0000, 0.4943, 0.0000, 1.0052, 0.0000, 0.7240, 0.0000, 0.2610, 0.0000,\n",
      "         0.5320, 0.7728, 0.0745, 0.0000, 0.0000, 0.0000, 0.0321, 0.0101, 0.5701,\n",
      "         0.0000, 1.0784, 0.3470, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.3932],\n",
      "        [0.5709, 0.0000, 0.0149, 0.3441, 0.0000, 0.0000, 0.0000, 0.0000, 0.0321,\n",
      "         0.0000, 0.7811, 0.3366, 0.0000, 0.0870, 0.0000, 0.0000, 0.0000, 0.1371,\n",
      "         0.0000, 0.5242, 0.2671, 0.0000, 0.0000, 0.0000, 0.4404, 0.4654, 0.8866,\n",
      "         0.0000, 0.0113, 0.0000, 0.2045, 0.0099, 0.2553, 0.7782, 0.0644, 0.0000,\n",
      "         0.0000, 0.4059, 0.0000, 0.8253, 0.0000, 0.5944, 0.0000, 0.2143, 0.0000,\n",
      "         0.4368, 0.6345, 0.0612, 0.0000, 0.0000, 0.0000, 0.0263, 0.0083, 0.4681,\n",
      "         0.0000, 0.8854, 0.2849, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.3228]], grad_fn=<ReluBackward0>)\n",
      "tensor([[0, 1, 1, 2],\n",
      "        [1, 0, 2, 1]])\n",
      "Output:\n",
      "Data(x=[3, 64], edge_index=[2, 4])\n",
      "Layer:       ReLU()\n",
      "LayerConfig: name='GCN3_Activation' input='GCN3' type='torch.nn.ReLU'\n",
      "Previous:    ['GCN3']\n",
      "Next:        ['AddPool']\n",
      "Inputs:      ['GCN3']\n",
      "[tensor([[230.]])]\n",
      "Output\n",
      "Data(x=[3, 64], edge_index=[2, 4])\n",
      "Layer:       GlobalPooling(aggr=sum)\n",
      "LayerConfig: name='AddPool' input='GCN3_Activation' type='app.features.model.layers.GlobalPooling' args=AppglobalpoolingArgs(aggr='sum')\n",
      "Previous:    ['GCN3_Activation']\n",
      "Next:        ['Combiner']\n",
      "Inputs:      ['GCN3_Activation']\n",
      "Input:\n",
      "tensor([[0.0000, 0.1380, 0.0000, 0.0000, 0.0000, 0.1219, 0.0000, 0.0000, 0.5640,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.1384, 0.0000, 0.0921, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.2239, 0.0000, 0.0000, 0.3693, 0.2801, 0.0000, 0.1962,\n",
      "         0.0000, 0.0172, 0.0355, 0.0814, 0.0000, 0.3381, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.2111, 0.1966, 0.3527, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0130, 0.4212, 0.0000, 0.0000, 0.0000, 0.4263, 0.0115, 0.2515,\n",
      "         0.0000, 0.0000, 0.0000, 0.2176, 0.0000, 0.0000, 0.0000, 0.0816, 0.0000,\n",
      "         0.1347],\n",
      "        [0.0000, 0.1692, 0.0000, 0.0000, 0.0000, 0.1494, 0.0000, 0.0000, 0.6914,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.1697, 0.0000, 0.1129, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.2745, 0.0000, 0.0000, 0.4527, 0.3433, 0.0000, 0.2406,\n",
      "         0.0000, 0.0211, 0.0435, 0.0998, 0.0000, 0.4145, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.2588, 0.2410, 0.4324, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0160, 0.5163, 0.0000, 0.0000, 0.0000, 0.5226, 0.0141, 0.3083,\n",
      "         0.0000, 0.0000, 0.0000, 0.2668, 0.0000, 0.0000, 0.0000, 0.1000, 0.0000,\n",
      "         0.1651],\n",
      "        [0.0000, 0.1380, 0.0000, 0.0000, 0.0000, 0.1219, 0.0000, 0.0000, 0.5640,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.1384, 0.0000, 0.0921, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.2239, 0.0000, 0.0000, 0.3693, 0.2801, 0.0000, 0.1962,\n",
      "         0.0000, 0.0172, 0.0355, 0.0814, 0.0000, 0.3381, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.2111, 0.1966, 0.3527, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0130, 0.4212, 0.0000, 0.0000, 0.0000, 0.4263, 0.0115, 0.2515,\n",
      "         0.0000, 0.0000, 0.0000, 0.2176, 0.0000, 0.0000, 0.0000, 0.0816, 0.0000,\n",
      "         0.1347]], grad_fn=<ReluBackward0>)\n",
      "None\n",
      "Output:\n",
      "tensor([[0.0000, 0.4452, 0.0000, 0.0000, 0.0000, 0.3932, 0.0000, 0.0000, 1.8195,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.4465, 0.0000, 0.2972, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.7224, 0.0000, 0.0000, 1.1914, 0.9035, 0.0000, 0.6330,\n",
      "         0.0000, 0.0556, 0.1145, 0.2626, 0.0000, 1.0908, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.6811, 0.6342, 1.1378, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0421, 1.3586, 0.0000, 0.0000, 0.0000, 1.3752, 0.0370, 0.8114,\n",
      "         0.0000, 0.0000, 0.0000, 0.7020, 0.0000, 0.0000, 0.0000, 0.2632, 0.0000,\n",
      "         0.4344]], grad_fn=<SumBackward1>)\n",
      "Layer:       Concat()\n",
      "LayerConfig: name='Combiner' input=['AddPool', 'Linear1'] type='app.features.model.layers.Concat'\n",
      "Previous:    ['AddPool', 'Linear1']\n",
      "Next:        ['LinearJoined']\n",
      "Inputs:      ['AddPool', 'Linear1']\n",
      "Inputs:\n",
      "[tensor([[0.0000, 0.4452, 0.0000, 0.0000, 0.0000, 0.3932, 0.0000, 0.0000, 1.8195,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.4465, 0.0000, 0.2972, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.7224, 0.0000, 0.0000, 1.1914, 0.9035, 0.0000, 0.6330,\n",
      "         0.0000, 0.0556, 0.1145, 0.2626, 0.0000, 1.0908, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.6811, 0.6342, 1.1378, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0421, 1.3586, 0.0000, 0.0000, 0.0000, 1.3752, 0.0370, 0.8114,\n",
      "         0.0000, 0.0000, 0.0000, 0.7020, 0.0000, 0.0000, 0.0000, 0.2632, 0.0000,\n",
      "         0.4344]], grad_fn=<SumBackward1>), tensor([[ 215.6506,  -49.1663,   18.2633,   -5.0933,  212.1023,  128.7159,\n",
      "         -138.5590,  -86.7516,  -88.1716,   37.0214]], grad_fn=<AddmmBackward>)]\n",
      "torch.Size([1, 64])\n",
      "torch.Size([1, 10])\n",
      "Output\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "torch.cat(): Sizes of tensors must match except in dimension 0. Got 64 and 10 in dimension 1 (The offending index is 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [41]\u001b[0m, in \u001b[0;36m<cell line: 111>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    108\u001b[0m                 \u001b[38;5;28mprint\u001b[39m(storage[layer_name])\n\u001b[1;32m    110\u001b[0m custom_model \u001b[38;5;241m=\u001b[39m CustomModel(model)\n\u001b[0;32m--> 111\u001b[0m \u001b[43mcustom_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_input\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [41]\u001b[0m, in \u001b[0;36mCustomModel.forward\u001b[0;34m(self, input_)\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;28mprint\u001b[39m(val\u001b[38;5;241m.\u001b[39msize())\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOutput\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 107\u001b[0m storage[layer_name] \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minput_values\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28mprint\u001b[39m(storage[layer_name])\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/torch/nn/modules/module.py:1051\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1047\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1048\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1049\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1052\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1053\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/app/app/features/model/layers/concat.py:10\u001b[0m, in \u001b[0;36mConcat.forward\u001b[0;34m(self, x1, x2)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x1: torch\u001b[38;5;241m.\u001b[39mTensor, x2: torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m---> 10\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx2\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: torch.cat(): Sizes of tensors must match except in dimension 0. Got 64 and 10 in dimension 1 (The offending index is 1)"
     ]
    }
   ],
   "source": [
    "# Implement module forward\n",
    "from typing import Dict, Union, List\n",
    "import torch\n",
    "import torch.nn\n",
    "import torch_geometric.nn as geom_nn\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "CustomDatasetIn = Dict[str, Union[torch.Tensor, Data]]\n",
    "\n",
    "def if_string_make_list(str_or_list: Union[str, List[str]]) -> List[str]:\n",
    "    if isinstance(str_or_list, str):\n",
    "        return [str_or_list]\n",
    "    return str_or_list\n",
    "\n",
    "class CustomModel(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, config: ModelConfig):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.config = config\n",
    "\n",
    "        layers_dict = {}\n",
    "        for layer in config.layers:\n",
    "            layers_dict[layer.name] = layer.create()\n",
    "\n",
    "        self.layers = torch.nn.ModuleDict(layers_dict)\n",
    "\n",
    "        self.layer_configs = {\n",
    "            l.name: l for l in config.layers\n",
    "        }\n",
    "\n",
    "        self.graph = config.make_graph()\n",
    "        self.topo_sorting = list(nx.topological_sort(self.graph))\n",
    "    \n",
    "    def forward(self, input_: CustomDatasetIn):\n",
    "        storage = input_.copy()\n",
    "\n",
    "        for index, node_name in enumerate(self.topo_sorting):\n",
    "            if not node_name in self.layers:\n",
    "                continue\n",
    "            layer_name = node_name\n",
    "            layer = self.layers[layer_name]\n",
    "            layer_config = self.layer_configs[layer_name]\n",
    "            previous_layers = [p_layer for p_layer, c_layer in self.graph.in_edges(layer_name)]\n",
    "            next_layers = [n_layer for c_layer, n_layer in self.graph.out_edges(layer_name)]\n",
    "            inputs = if_string_make_list(layer_config.input)\n",
    "            print(f'Layer:       {layer}')\n",
    "            print(f'LayerConfig: {layer_config}')\n",
    "            print(f'Previous:    {previous_layers}')\n",
    "            print(f'Next:        {next_layers}')\n",
    "            print(f'Inputs:      {inputs}')\n",
    "            # Step 2\n",
    "            # Transform and preprocess the input and output based on the previous\n",
    "            # and next layers.\n",
    "            \n",
    "            if is_message_passing(layer):\n",
    "                assert len(inputs) == 1, f\"Length of a gnn layer's inputs should be at most 1. inputs = {inputs}\"\n",
    "                input_source = inputs[0]\n",
    "                x, edge_index = storage[input_source].x, storage[input_source].edge_index\n",
    "                print('Input:')\n",
    "                print(x)\n",
    "                print(edge_index)\n",
    "                x, edge_index = layer(x=x, edge_index=edge_index), edge_index\n",
    "                storage[layer_name] = Data(x=x, edge_index=edge_index)\n",
    "                print('Output:')\n",
    "                print(storage[layer_name])\n",
    "            # 2.2   - if its an pooling layer it always have just one input\n",
    "            #         and the input is composed by x (node_features) from the last layer\n",
    "            #         and the batch that comes with the data object\n",
    "            elif is_graph_pooling(layer):\n",
    "                assert len(inputs) == 1, f\"Length of a gnn layer's inputs should be at most 1. inputs = {inputs}\"\n",
    "                input_source = inputs[0]\n",
    "                x, edge_index, batch = storage[input_source].x, storage[input_source].edge_index, storage[input_source].batch\n",
    "                storage[layer_name] = layer(x=x, batch=batch)\n",
    "                print('Input:')\n",
    "                print(x)\n",
    "                print(batch)\n",
    "                print('Output:')\n",
    "                print(storage[layer_name])\n",
    "            # 2.3   - if its an activation or a mlp/normal layer we need to check the\n",
    "            #         previous layers to make sure that the input is in t;he correct format\n",
    "            #         and check the next layers to format the output\n",
    "            elif is_graph_activation(layer, self.layers, previous_layers):\n",
    "                assert len(inputs) == 1, f\"Length of a activation layer's inputs should be at most 1. inputs = {inputs}\"\n",
    "                src = inputs[0]\n",
    "                if isinstance(storage[src], Data):\n",
    "                    x, edge_index = storage[src].x, storage[src].edge_index\n",
    "                    storage[layer_name] = Data(x=layer(x), edge_index=edge_index)\n",
    "                else:\n",
    "                    x = storage[src]\n",
    "                    storage[layer_name] = layer(x)\n",
    "                    print('Inputs:')\n",
    "                print(input_values)\n",
    "                print('Output')\n",
    "                print(storage[layer_name])\n",
    "            else: # elif is_linear_or_activation(layer) or is_concat(layer) :\n",
    "                input_values = [ \n",
    "                    storage[input] if isinstance(storage[input], Data) else\n",
    "                    storage[input]\n",
    "                    for input in inputs\n",
    "                ]\n",
    "                print('Inputs:')\n",
    "                print(input_values)\n",
    "                for val in input_values:\n",
    "                    print(val.size())\n",
    "                print('Output')\n",
    "                storage[layer_name] = layer(*input_values)\n",
    "                print(storage[layer_name])\n",
    "                \n",
    "custom_model = CustomModel(model)\n",
    "custom_model.forward(dataset_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "c09757cb-602c-430b-9719-d0675baacab0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CustomModel(\n",
       "  (layers): ModuleDict(\n",
       "    (GCN1): GCNConv(30, 64)\n",
       "    (GCN1_Activation): ReLU()\n",
       "    (GCN2): GCNConv(64, 64)\n",
       "    (GCN2_Activation): ReLU()\n",
       "    (GCN3): GCNConv(64, 64)\n",
       "    (GCN3_Activation): ReLU()\n",
       "    (AddPool): GlobalPooling(aggr=sum)\n",
       "    (Linear1): Linear(in_features=1, out_features=10, bias=True)\n",
       "    (Combiner): Concat()\n",
       "    (LinearJoined): Linear(in_features=74, out_features=1, bias=True)\n",
       "    (OutputSigmoid): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Implement module forward\n",
    "from typing import Dict, Union\n",
    "import torch\n",
    "import torch.nn\n",
    "import torch_geometric.nn as geom_nn\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "CustomDatasetIn = Dict[str, Union[torch.Tensor, Data]]\n",
    "\n",
    "def if_string_make_list(str_or_list: Union[str, List[str]]) -> List[str]:\n",
    "    if isinstance(str_or_list, str):\n",
    "        return [str_or_list]\n",
    "    return str_or_list\n",
    "\n",
    "class CustomModel(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, config: ModelConfig):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.config = config\n",
    "\n",
    "        layers_dict = {}\n",
    "        for layer in config.layers:\n",
    "            layers_dict[layer.name] = layer.create()\n",
    "\n",
    "        self.layers = torch.nn.ModuleDict(layers_dict)\n",
    "\n",
    "        self.layer_configs = {\n",
    "            l.name: l for l in config.layers\n",
    "        }\n",
    "\n",
    "        self.graph = config.make_graph()\n",
    "        self.topo_sorting = list(nx.topological_sort(self.graph))\n",
    "    \n",
    "    def forward(self, input_: CustomDatasetIn):\n",
    "        storage = input_.copy()\n",
    "\n",
    "        for index, node_name in enumerate(self.topo_sorting):\n",
    "            if not node_name in self.layers:\n",
    "                continue\n",
    "            layer_name = node_name\n",
    "            layer = self.layers[layer_name]\n",
    "            layer_config = self.layer_configs[layer_name]\n",
    "            previous_layers = [p_layer for p_layer, c_layer in self.graph.in_edges(layer_name)]\n",
    "            next_layers = [n_layer for c_layer, n_layer in self.graph.out_edges(layer_name)]\n",
    "            inputs = if_string_make_list(layer_config.input)\n",
    "            print(f'Layer:       {layer}')\n",
    "            print(f'LayerConfig: {layer_config}')\n",
    "            print(f'Previous:    {previous_layers}')\n",
    "            print(f'Next:        {next_layers}')\n",
    "            print(f'Inputs:      {inputs}')\n",
    "            # Step 2\n",
    "            # Transform and preprocess the input and output based on the previous\n",
    "            # and next layers.\n",
    "            # 2.1   - if its an gnn layer it always have just one input\n",
    "            if is_message_passing(layer):\n",
    "                input_source = self.layer_configs[layer_name].input\n",
    "                # Check if comes from other layer or the dataset\n",
    "                if not input_source in self.layers:\n",
    "                    # If comes from the dataset we need to extract the x and edge_index\n",
    "                    x, edge_index = storage[input_source]['x'], storage[input_source]['edge_index']\n",
    "\n",
    "                    print('\\tInput:')\n",
    "                    print('\\t\\t', x)\n",
    "                    print('\\t\\t', edge_index)\n",
    "\n",
    "                    layer_output = layer(x=x, edge_index=edge_index), edge_index\n",
    "                    print('\\tOutput:')\n",
    "                    print('\\t\\t', layer_output)\n",
    "\n",
    "                else:\n",
    "                    # Otherwise we take as an input a tuple containing the x (node_features)\n",
    "                    # in the first position and edge_index in the second.\n",
    "                    continue\n",
    "                    # TODO: verify if we need to pass the batch with the other features \n",
    "                    x, edge_index = storage[input_source][0], storage[input_source][1]\n",
    "                    layer_output = layer(x=x, edge_index=edge_index), edge_index\n",
    "\n",
    "            # 2.2   - if its an pooling layer it always have just one input\n",
    "            #         and the input is composed by x (node_features) from the last layer\n",
    "            #         and the batch that comes with the data object\n",
    "\n",
    "            # 2.3   - if its an activation or a mlp/normal layer we need to check the\n",
    "            #         previous layers to make sure that the input is in the correct format\n",
    "            #         and check the next layers to format the output\n",
    "            else:\n",
    "                input_source = self.layer_configs[layer_name].input\n",
    "                input_source = [input_source]  else input_source\n",
    "                # [mwt]\n",
    "                # [GCN1]\n",
    "                if isinstance(input_source, str): # Only had one previous layer\n",
    "                    # If just had one feature to pass we need to check the previous layer\n",
    "                    # and them determine if we pass the edge_index for the next layer\n",
    "                    if isinstance(storage[input_source], tuple):\n",
    "                        # In this case we receive from a MessagePassing\n",
    "                        \n",
    "                        # We also need to check if the next layer is a MessagePassing\n",
    "                        has_gnn_next = False\n",
    "                        for n_layer in next_layers:\n",
    "                            if self.layers[]\n",
    "                        next_layers\n",
    "                    print(previous_layers[0].)\n",
    "                else:\n",
    "                    # [Linear1, AddPool]\n",
    "                    pass\n",
    "                    \n",
    "                print('\\t', input_source)\n",
    "\n",
    "            # 2.3.1 - if the next layer is a gnn layer we need to recover the correct edge_index\n",
    "            #         if the next layer is a normal layer we just need the result\n",
    "\n",
    "            ###### OLD - FORWARD ###### \n",
    "\n",
    "#             inputs = self.layer_configs[layer_name].input\n",
    "\n",
    "#             if isinstance(inputs, str): # arrays only\n",
    "#                 inputs = [inputs]\n",
    "\n",
    "#             inps = [ outs[input] for input in inputs ]\n",
    "\n",
    "#             if is_message_passing(layer):\n",
    "#                 inp = inps[0]\n",
    "#                 print(f'\\tInput: {inp}')\n",
    "\n",
    "#                 # Detect if the inp is an Data object, otherwise we need to access a dict\n",
    "#                 # returned from other GCN layer\n",
    "#                 if isinstance(inp, Data):\n",
    "#                     x, edge_index = inp.x, inp.edge_index\n",
    "#                 else:\n",
    "#                     x, edge_index = inp['x'], inp['edge_index']\n",
    "\n",
    "#                 # Out preprocess\n",
    "#                 x = layer(x, edge_index) # We need to store the edge_index for other layers to use them\n",
    "#                 outs[layer_name] = dict(x=x, edge_index=edge_index)\n",
    "\n",
    "#             elif is_graph_pooling(layer):\n",
    "#                 inp = inps[0]\n",
    "#                 print(f'\\tInput: {inp}')\n",
    "#                 # x, batch = inp.x, inp.batch\n",
    "#                 # outs[layer_name] = layer(x, batch)\n",
    "\n",
    "#             else: # concat layers and normal layers\n",
    "#                 transformed_input = inps.copy()\n",
    "\n",
    "#                 if isinstance(transformed_input[0], dict):\n",
    "#                     transformed_input[0] = inps[0]['x']\n",
    "\n",
    "#                 print(f'\\tInput: {inps}')\n",
    "\n",
    "#                 # Detect if the next layer is a gnn layer\n",
    "#                 next_layers = [e[1] for e in self.graph.out_edges(layer_name)]\n",
    "#                 next_layer_is_gnn = False\n",
    "\n",
    "#                 x = layer(*transformed_input)\n",
    "\n",
    "#                 for nl in next_layers:\n",
    "#                     if is_message_passing(self.layers[nl]):\n",
    "#                         # Means that the next layer is a gcn layer\n",
    "#                         next_layer_is_gnn = True\n",
    "#                 if next_layer_is_gnn:\n",
    "#                     # Adapt the output to a MessagePassing input format\n",
    "#                     outs[layer_name] = dict(x=x, edge_index=inps[0]['edge_index'])\n",
    "#                 else:\n",
    "#                     outs[layer_name] = x\n",
    "\n",
    "#             # last = outs[layer_name]\n",
    "        \n",
    "#         return None\n",
    "\n",
    "custom_model = CustomModel(model)\n",
    "custom_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "3fbfb685-bcc2-467d-85ff-640632681c8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCNConv(30, 64)\n",
      "\tInput:\n",
      "\t\t tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])\n",
      "\t\t tensor([[0, 1, 1, 2],\n",
      "        [1, 0, 2, 1]])\n",
      "\tOutput:\n",
      "\t\t (tensor([[-0.7560,  0.0658, -0.0796,  0.9487, -1.0943, -0.4712, -0.6284, -0.9453,\n",
      "          0.4003, -0.1058, -0.8314, -0.2375, -0.1342, -0.8229, -0.0595, -0.5776,\n",
      "          0.2084,  0.5101, -1.2855, -0.4165, -0.6712, -0.3578, -0.2476,  0.4144,\n",
      "         -0.2185, -0.6165, -0.0130, -0.3918, -0.9680, -0.9675,  0.4271,  0.2209,\n",
      "         -0.3075,  0.3070, -0.9903, -0.0725, -0.0527,  0.4657,  0.6364, -1.3483,\n",
      "          0.5058,  0.8158,  0.1217,  1.1105, -0.2134, -0.4581,  0.2792,  0.8900,\n",
      "         -0.7743,  0.0249, -0.4545, -0.3475,  0.6694, -1.0571, -0.3278, -0.2066,\n",
      "         -0.0414,  0.4588, -0.5291, -0.5987, -0.0754, -0.9336,  0.2716,  0.8282],\n",
      "        [-0.9571,  0.0832, -0.1008,  1.2010, -1.3854, -0.5965, -0.7955, -1.1967,\n",
      "          0.5068, -0.1339, -1.0526, -0.3007, -0.1700, -1.0418, -0.0753, -0.7313,\n",
      "          0.2638,  0.6458, -1.6274, -0.5272, -0.8497, -0.4530, -0.3134,  0.5247,\n",
      "         -0.2766, -0.7804, -0.0164, -0.4960, -1.2254, -1.2249,  0.5407,  0.2797,\n",
      "         -0.3893,  0.3887, -1.2537, -0.0918, -0.0667,  0.5896,  0.8057, -1.7069,\n",
      "          0.6403,  1.0328,  0.1541,  1.4059, -0.2702, -0.5800,  0.3535,  1.1267,\n",
      "         -0.9803,  0.0315, -0.5754, -0.4399,  0.8474, -1.3383, -0.4149, -0.2616,\n",
      "         -0.0524,  0.5808, -0.6699, -0.7579, -0.0954, -1.1820,  0.3439,  1.0485],\n",
      "        [-0.7560,  0.0658, -0.0796,  0.9487, -1.0943, -0.4712, -0.6284, -0.9453,\n",
      "          0.4003, -0.1058, -0.8314, -0.2375, -0.1342, -0.8229, -0.0595, -0.5776,\n",
      "          0.2084,  0.5101, -1.2855, -0.4165, -0.6712, -0.3578, -0.2476,  0.4144,\n",
      "         -0.2185, -0.6165, -0.0130, -0.3918, -0.9680, -0.9675,  0.4271,  0.2209,\n",
      "         -0.3075,  0.3070, -0.9903, -0.0725, -0.0527,  0.4657,  0.6364, -1.3483,\n",
      "          0.5058,  0.8158,  0.1217,  1.1105, -0.2134, -0.4581,  0.2792,  0.8900,\n",
      "         -0.7743,  0.0249, -0.4545, -0.3475,  0.6694, -1.0571, -0.3278, -0.2066,\n",
      "         -0.0414,  0.4588, -0.5291, -0.5987, -0.0754, -0.9336,  0.2716,  0.8282]],\n",
      "       grad_fn=<AddBackward0>), tensor([[0, 1, 1, 2],\n",
      "        [1, 0, 2, 1]]))\n",
      "Linear(in_features=1, out_features=10, bias=True)\n",
      "\t ['mwt']\n",
      "ReLU()\n",
      "\t ['GCN1']\n",
      "GCNConv(64, 64)\n",
      "ReLU()\n",
      "\t ['GCN2']\n",
      "GCNConv(64, 64)\n",
      "ReLU()\n",
      "\t ['GCN3']\n",
      "GlobalPooling(aggr=sum)\n",
      "\t ['GCN3_Activation']\n",
      "Concat()\n",
      "\t ['AddPool', 'Linear1']\n",
      "Linear(in_features=74, out_features=1, bias=True)\n",
      "\t ['Combiner']\n",
      "Sigmoid()\n",
      "\t ['LinearJoined']\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
