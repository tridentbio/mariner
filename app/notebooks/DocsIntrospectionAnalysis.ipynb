{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e2f7367-a2c0-4a26-a3ea-4bafd4029739",
   "metadata": {},
   "source": [
    "# Documentation introspection Aalysis\n",
    "\n",
    "1. Get the documentation URL:\n",
    "    This can be done by using the documentation path from the lib. I the case of pytorch, it is\n",
    "    `https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear`\n",
    "    and for pygnn it is `https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.nn.conv.GCNConv`\n",
    "    In both cases we just need to subtitute the URL hash fragment in the end\n",
    "2. Get the docs strign andn remove unwanted sections from it, such as the Examples section\n",
    "3. Figure out how many inputs and outputs the graph editor node component will have "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77c5fdf-04f7-49e7-8b3b-79ae77c591b2",
   "metadata": {},
   "source": [
    "## 1. Get the documentation URL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44c2b4ac-d446-400a-9340-7bcd631580fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[None, None, 'https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear', 'https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Sigmoid', 'https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.ReLU', 'https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.nn.GCNConv', None]\n"
     ]
    }
   ],
   "source": [
    "from app.features.model.generate import layers, featurizers\n",
    "\n",
    "def is_from_pygnn(class_path: str) -> bool:\n",
    "    return class_path.startswith('torch_geometric.')\n",
    "\n",
    "def is_from_pytorch(class_path: str) -> bool:\n",
    "    return class_path.startswith('torch.')\n",
    "\n",
    "def get_documentation_link(component) -> str:\n",
    "    if is_from_pygnn(component.name):\n",
    "        return f'https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#{component.name}'\n",
    "    elif is_from_pytorch(component.name):\n",
    "        return f'https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#{component.name}'\n",
    "    return None\n",
    "    \n",
    "print([ get_documentation_link(comp) for comp in layers + featurizers ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc2bbda7-c08a-4699-81e8-78e686a68a47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src_lib</th>\n",
       "      <th>docs</th>\n",
       "      <th>has_examples</th>\n",
       "      <th>has_args</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>torch_geometric.nn.GCNConv</th>\n",
       "      <td>pygnn</td>\n",
       "      <td>The graph convolutional operator from the `\"Se...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>torch.nn.Linear</th>\n",
       "      <td>torch</td>\n",
       "      <td>Applies a linear transformation to the incomin...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>torch.nn.Sigmoid</th>\n",
       "      <td>torch</td>\n",
       "      <td>Applies the element-wise function:\\n\\n    .. m...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>torch.nn.ReLU</th>\n",
       "      <td>torch</td>\n",
       "      <td>Applies the rectified linear unit function ele...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>app.features.model.layers.GlobalPooling</th>\n",
       "      <td>app</td>\n",
       "      <td>A global pooling module that wraps the usage o...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>app.features.model.layers.Concat</th>\n",
       "      <td>app</td>\n",
       "      <td>\\n    A helper layer that concatenates the out...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>app.features.model.featurizers.MoleculeFeaturizer</th>\n",
       "      <td>app</td>\n",
       "      <td>\\n    Small molecule featurizer.\\n    Args:\\n ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  src_lib  \\\n",
       "torch_geometric.nn.GCNConv                          pygnn   \n",
       "torch.nn.Linear                                     torch   \n",
       "torch.nn.Sigmoid                                    torch   \n",
       "torch.nn.ReLU                                       torch   \n",
       "app.features.model.layers.GlobalPooling               app   \n",
       "app.features.model.layers.Concat                      app   \n",
       "app.features.model.featurizers.MoleculeFeaturizer     app   \n",
       "\n",
       "                                                                                                docs  \\\n",
       "torch_geometric.nn.GCNConv                         The graph convolutional operator from the `\"Se...   \n",
       "torch.nn.Linear                                    Applies a linear transformation to the incomin...   \n",
       "torch.nn.Sigmoid                                   Applies the element-wise function:\\n\\n    .. m...   \n",
       "torch.nn.ReLU                                      Applies the rectified linear unit function ele...   \n",
       "app.features.model.layers.GlobalPooling            A global pooling module that wraps the usage o...   \n",
       "app.features.model.layers.Concat                   \\n    A helper layer that concatenates the out...   \n",
       "app.features.model.featurizers.MoleculeFeaturizer  \\n    Small molecule featurizer.\\n    Args:\\n ...   \n",
       "\n",
       "                                                   has_examples  has_args  \n",
       "torch_geometric.nn.GCNConv                                    0         1  \n",
       "torch.nn.Linear                                               1         1  \n",
       "torch.nn.Sigmoid                                              1         0  \n",
       "torch.nn.ReLU                                                 1         1  \n",
       "app.features.model.layers.GlobalPooling                       0         1  \n",
       "app.features.model.layers.Concat                              0         0  \n",
       "app.features.model.featurizers.MoleculeFeaturizer             0         1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from app.features.model.generate import layers, featurizers\n",
    "from app.features.model.utils import get_class_from_path_string\n",
    "\n",
    "\n",
    "alldocs = [\n",
    "    (layer.name, get_class_from_path_string(layer.name).__doc__)\n",
    "    for layer in layers + featurizers\n",
    "]\n",
    "def get_by_first_start(tuples, first_start):\n",
    "    return [\n",
    "        item\n",
    "        for item in tuples\n",
    "        if item[0].startswith(first_start)\n",
    "    ]\n",
    "\n",
    "torch_geometric_comps = get_by_first_start(alldocs, 'torch_geometric.')\n",
    "torch_comps = get_by_first_start(alldocs, 'torch.')\n",
    "app_comps = get_by_first_start(alldocs, 'app.')\n",
    "\n",
    "def has_examples(docs):\n",
    "    return 'Examples:' in docs\n",
    "\n",
    "\n",
    "def has_args(docs):\n",
    "    return 'Args:\\n' in docs\n",
    "\n",
    "def has_docs(docs):\n",
    "    return docs is not None and len(docs) > 0\n",
    "\n",
    "df = pd.DataFrame({ 'src_lib': [], 'docs': [], 'has_examples': [], 'has_args': [], 'has_examples': [] })\n",
    "def info(title, stuff, df):\n",
    "    for (class_path, docs) in stuff:\n",
    "        df.loc[class_path] = {\n",
    "            'docs': docs,\n",
    "            'src_lib': title,\n",
    "            'has_args': int(has_args(docs)),\n",
    "            'has_examples': int(has_examples(docs))\n",
    "        }\n",
    "    \n",
    "info('pygnn', torch_geometric_comps, df)\n",
    "info('torch', torch_comps, df)\n",
    "info('app', app_comps, df)\n",
    "df.loc[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c2c5bc4-0b6c-46e0-817c-a9b1a81e0c3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applies a linear transformation to the incoming data: :math:`y = xA^T + b`\n",
      "\n",
      "    This module supports :ref:`TensorFloat32<tf32_on_ampere>`.\n",
      "\n",
      "    Args:\n",
      "        in_features: size of each input sample\n",
      "        out_features: size of each output sample\n",
      "        bias: If set to ``False``, the layer will not learn an additive bias.\n",
      "            Default: ``True``\n",
      "\n",
      "    Shape:\n",
      "        - Input: :math:`(N, *, H_{in})` where :math:`*` means any number of\n",
      "          additional dimensions and :math:`H_{in} = \\text{in\\_features}`\n",
      "        - Output: :math:`(N, *, H_{out})` where all but the last dimension\n",
      "          are the same shape as the input and :math:`H_{out} = \\text{out\\_features}`.\n",
      "\n",
      "    Attributes:\n",
      "        weight: the learnable weights of the module of shape\n",
      "            :math:`(\\text{out\\_features}, \\text{in\\_features})`. The values are\n",
      "            initialized from :math:`\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})`, where\n",
      "            :math:`k = \\frac{1}{\\text{in\\_features}}`\n",
      "        bias:   the learnable bias of the module of shape :math:`(\\text{out\\_features})`.\n",
      "                If :attr:`bias` is ``True``, the values are initialized from\n",
      "                :math:`\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})` where\n",
      "                :math:`k = \\frac{1}{\\text{in\\_features}}`\n",
      "\n",
      "    Examples::\n",
      "\n",
      "        >>> m = nn.Linear(20, 30)\n",
      "        >>> input = torch.randn(128, 20)\n",
      "        >>> output = m(input)\n",
      "        >>> print(output.size())\n",
      "        torch.Size([128, 30])\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(df.loc['torch.nn.Linear', 'docs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9743510-ea8c-4d91-9891-ce51c686c8de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The graph convolutional operator from the `\"Semi-supervised\n",
      "    Classification with Graph Convolutional Networks\"\n",
      "    <https://arxiv.org/abs/1609.02907>`_ paper\n",
      "\n",
      "    .. math::\n",
      "        \\mathbf{X}^{\\prime} = \\mathbf{\\hat{D}}^{-1/2} \\mathbf{\\hat{A}}\n",
      "        \\mathbf{\\hat{D}}^{-1/2} \\mathbf{X} \\mathbf{\\Theta},\n",
      "\n",
      "    where :math:`\\mathbf{\\hat{A}} = \\mathbf{A} + \\mathbf{I}` denotes the\n",
      "    adjacency matrix with inserted self-loops and\n",
      "    :math:`\\hat{D}_{ii} = \\sum_{j=0} \\hat{A}_{ij}` its diagonal degree matrix.\n",
      "    The adjacency matrix can include other values than :obj:`1` representing\n",
      "    edge weights via the optional :obj:`edge_weight` tensor.\n",
      "\n",
      "    Its node-wise formulation is given by:\n",
      "\n",
      "    .. math::\n",
      "        \\mathbf{x}^{\\prime}_i = \\mathbf{\\Theta}^{\\top} \\sum_{j \\in\n",
      "        \\mathcal{N}(v) \\cup \\{ i \\}} \\frac{e_{j,i}}{\\sqrt{\\hat{d}_j\n",
      "        \\hat{d}_i}} \\mathbf{x}_j\n",
      "\n",
      "    with :math:`\\hat{d}_i = 1 + \\sum_{j \\in \\mathcal{N}(i)} e_{j,i}`, where\n",
      "    :math:`e_{j,i}` denotes the edge weight from source node :obj:`j` to target\n",
      "    node :obj:`i` (default: :obj:`1.0`)\n",
      "\n",
      "    Args:\n",
      "        in_channels (int): Size of each input sample, or :obj:`-1` to derive\n",
      "            the size from the first input(s) to the forward method.\n",
      "        out_channels (int): Size of each output sample.\n",
      "        improved (bool, optional): If set to :obj:`True`, the layer computes\n",
      "            :math:`\\mathbf{\\hat{A}}` as :math:`\\mathbf{A} + 2\\mathbf{I}`.\n",
      "            (default: :obj:`False`)\n",
      "        cached (bool, optional): If set to :obj:`True`, the layer will cache\n",
      "            the computation of :math:`\\mathbf{\\hat{D}}^{-1/2} \\mathbf{\\hat{A}}\n",
      "            \\mathbf{\\hat{D}}^{-1/2}` on first execution, and will use the\n",
      "            cached version for further executions.\n",
      "            This parameter should only be set to :obj:`True` in transductive\n",
      "            learning scenarios. (default: :obj:`False`)\n",
      "        add_self_loops (bool, optional): If set to :obj:`False`, will not add\n",
      "            self-loops to the input graph. (default: :obj:`True`)\n",
      "        normalize (bool, optional): Whether to add self-loops and compute\n",
      "            symmetric normalization coefficients on the fly.\n",
      "            (default: :obj:`True`)\n",
      "        bias (bool, optional): If set to :obj:`False`, the layer will not learn\n",
      "            an additive bias. (default: :obj:`True`)\n",
      "        **kwargs (optional): Additional arguments of\n",
      "            :class:`torch_geometric.nn.conv.MessagePassing`.\n",
      "\n",
      "    Shapes:\n",
      "        - **input:**\n",
      "          node features :math:`(|\\mathcal{V}|, F_{in})`,\n",
      "          edge indices :math:`(2, |\\mathcal{E}|)`,\n",
      "          edge weights :math:`(|\\mathcal{E}|)` *(optional)*\n",
      "        - **output:** node features :math:`(|\\mathcal{V}|, F_{out})`\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(df.loc['torch_geometric.nn.GCNConv', 'docs'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f820f8a4-a4d6-435a-a003-b3e4daef2ace",
   "metadata": {},
   "source": [
    "### Removing Sections of the docs\n",
    "To make the doc. simpler, we need to remove sections that refer exclusivelly to coding such as the Examples section\n",
    "\n",
    "As can be seen, documentation is divided by indentation blocks.\n",
    "\n",
    "So an ideia to remove sections is to find it's title, and the next indentation block. then slice it off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a49dbdf9-faf8-4061-8363-782334cdc2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def count_tabs(line: str):\n",
    "    # naive loop over chars\n",
    "    total = 0\n",
    "    for c in line:\n",
    "        if c == ' ' or c == '\\t':\n",
    "            total += 1\n",
    "        else:\n",
    "            break\n",
    "    return total\n",
    "\n",
    "def remove_indentation_of_section(text: str, section_title: str) -> str:\n",
    "    lines = text.split('\\n')\n",
    "    start_idx = None\n",
    "    tab_size = None\n",
    "    end_idx = None\n",
    "    for idx, line in enumerate(lines):\n",
    "        if section_title in line:\n",
    "            start_idx = idx\n",
    "            end_idx = start_idx\n",
    "            tab_size = count_tabs(line) + 4\n",
    "            continue\n",
    "        if start_idx is not None and count_tabs(line) >= tab_size:\n",
    "            end_idx += 1\n",
    "        elif start_idx is not None:\n",
    "            break\n",
    "    if start_idx is None:\n",
    "        return text\n",
    "    return '\\n'.join(lines[:start_idx] + lines[end_idx+1:])\n",
    "def test_remove_indentation():\n",
    "    assert remove_indentation_of_section('''The graph convolutional operator from the `\"Semi-supervised\n",
    "    Classification with Graph Convolutional Networks\"\n",
    "    <https://arxiv.org/abs/1609.02907>`_ paper\n",
    "\n",
    "    .. math::\n",
    "        \\mathbf{X}^{\\prime} = \\mathbf{\\hat{D}}^{-1/2} \\mathbf{\\hat{A}}\n",
    "        \\mathbf{\\hat{D}}^{-1/2} \\mathbf{X} \\mathbf{\\Theta},\n",
    "\n",
    "    where :math:`\\mathbf{\\hat{A}} = \\mathbf{A} + \\mathbf{I}` denotes the\n",
    "    adjacency matrix with inserted self-loops and\n",
    "    :math:`\\hat{D}_{ii} = \\sum_{j=0} \\hat{A}_{ij}` its diagonal degree matrix.\n",
    "    The adjacency matrix can include other values than :obj:`1` representing\n",
    "    edge weights via the optional :obj:`edge_weight` tensor.\n",
    "\n",
    "    Its node-wise formulation is given by:\n",
    "\n",
    "    .. math::\n",
    "        \\mathbf{x}^{\\prime}_i = \\mathbf{\\Theta}^{\\top} \\sum_{j \\in\n",
    "        \\mathcal{N}(v) \\cup \\{ i \\}} \\frac{e_{j,i}}{\\sqrt{\\hat{d}_j\n",
    "        \\hat{d}_i}} \\mathbf{x}_j\n",
    "\n",
    "    with :math:`\\hat{d}_i = 1 + \\sum_{j \\in \\mathcal{N}(i)} e_{j,i}`, where\n",
    "    :math:`e_{j,i}` denotes the edge weight from source node :obj:`j` to target\n",
    "    node :obj:`i` (default: :obj:`1.0`)\n",
    "\n",
    "    Args:\n",
    "        in_channels (int): Size of each input sample, or :obj:`-1` to derive\n",
    "            the size from the first input(s) to the forward method.\n",
    "        out_channels (int): Size of each output sample.\n",
    "        improved (bool, optional): If set to :obj:`True`, the layer computes\n",
    "            :math:`\\mathbf{\\hat{A}}` as :math:`\\mathbf{A} + 2\\mathbf{I}`.\n",
    "            (default: :obj:`False`)\n",
    "        cached (bool, optional): If set to :obj:`True`, the layer will cache\n",
    "            the computation of :math:`\\mathbf{\\hat{D}}^{-1/2} \\mathbf{\\hat{A}}\n",
    "            \\mathbf{\\hat{D}}^{-1/2}` on first execution, and will use the\n",
    "            cached version for further executions.\n",
    "            This parameter should only be set to :obj:`True` in transductive\n",
    "            learning scenarios. (default: :obj:`False`)\n",
    "        add_self_loops (bool, optional): If set to :obj:`False`, will not add\n",
    "            self-loops to the input graph. (default: :obj:`True`)\n",
    "        normalize (bool, optional): Whether to add self-loops and compute\n",
    "            symmetric normalization coefficients on the fly.\n",
    "            (default: :obj:`True`)\n",
    "        bias (bool, optional): If set to :obj:`False`, the layer will not learn\n",
    "            an additive bias. (default: :obj:`True`)\n",
    "        **kwargs (optional): Additional arguments of\n",
    "            :class:`torch_geometric.nn.conv.MessagePassing`.\n",
    "\n",
    "    Shapes:''', 'Args') == '''The graph convolutional operator from the `\"Semi-supervised\n",
    "    Classification with Graph Convolutional Networks\"\n",
    "    <https://arxiv.org/abs/1609.02907>`_ paper\n",
    "\n",
    "    .. math::\n",
    "        \\mathbf{X}^{\\prime} = \\mathbf{\\hat{D}}^{-1/2} \\mathbf{\\hat{A}}\n",
    "        \\mathbf{\\hat{D}}^{-1/2} \\mathbf{X} \\mathbf{\\Theta},\n",
    "\n",
    "    where :math:`\\mathbf{\\hat{A}} = \\mathbf{A} + \\mathbf{I}` denotes the\n",
    "    adjacency matrix with inserted self-loops and\n",
    "    :math:`\\hat{D}_{ii} = \\sum_{j=0} \\hat{A}_{ij}` its diagonal degree matrix.\n",
    "    The adjacency matrix can include other values than :obj:`1` representing\n",
    "    edge weights via the optional :obj:`edge_weight` tensor.\n",
    "\n",
    "    Its node-wise formulation is given by:\n",
    "\n",
    "    .. math::\n",
    "        \\mathbf{x}^{\\prime}_i = \\mathbf{\\Theta}^{\\top} \\sum_{j \\in\n",
    "        \\mathcal{N}(v) \\cup \\{ i \\}} \\frac{e_{j,i}}{\\sqrt{\\hat{d}_j\n",
    "        \\hat{d}_i}} \\mathbf{x}_j\n",
    "\n",
    "    with :math:`\\hat{d}_i = 1 + \\sum_{j \\in \\mathcal{N}(i)} e_{j,i}`, where\n",
    "    :math:`e_{j,i}` denotes the edge weight from source node :obj:`j` to target\n",
    "    node :obj:`i` (default: :obj:`1.0`)\n",
    "\n",
    "\n",
    "    Shapes:'''\n",
    "    \n",
    "test_remove_indentation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c687e75-0360-4037-80d7-a3e019abf00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: make sure Examples sections are removed"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
